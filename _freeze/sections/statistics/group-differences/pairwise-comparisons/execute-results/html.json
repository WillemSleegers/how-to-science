{
  "hash": "1ab978b7d642667702403b217febdbc9",
  "result": {
    "markdown": "---\ntitle: \"Pairwise comparisons\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(brms)\nlibrary(emmeans)\n\n# Set the default ggplot theme\ntheme_set(theme_minimal())\n```\n:::\n\n\nThis section is about different statistical techniques to analyze group differences.\n\n## Bayesian\n\n### Pairwise comparisons\n\nIn this scenario we simulate data from a study with 5 different groups. The conditions differ from each by a small amount and for simplicity's sake each condition has a standard deviation of 1. The sample size per condition is 250.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the simulation parameters\nMs <- c(0, 0.1, 0.2, 0.3, 0.4)\nSDs <- 1\nn <- 250\n\n# Produce the variance-covariance matrix\nSigma <- matrix(\n  nrow = length(Ms), \n  ncol = length(Ms), \n  data = c(\n    SDs^2, 0, 0, 0, 0,\n    0, SDs^2, 0, 0, 0,\n    0, 0, SDs^2, 0, 0,\n    0, 0, 0, SDs^2, 0,\n    0, 0, 0, 0, SDs^2\n  )\n)\n\n# Simulate the values\nm <- mvrnorm(n = n, mu = Ms, Sigma = Sigma, empirical = TRUE)\n\n# Prepare the data by converting it to a data frame and making it tidy\ncolnames(m) <- c(\"A\", \"B\", \"C\", \"D\", \"E\")\n\ndata <- as_tibble(m)\n\ndata <- pivot_longer(\n  data = data, \n  cols = everything(), \n  names_to = \"condition\", \n  values_to = \"DV\"\n)\n\ndata <- mutate(data, id = 1:n(), .before = condition)\n```\n:::\n\n\nTo perform the pairwise comparisons we first fit a model with `brms`. If we also want to calculate Bayes factors, we need to set a prior for the intercept. For technical reasons, this needs to be done by explicitly including the intercept in the formula. After that we need to set 3 priors: 1 for the intercept, 1 for all the other coefficients, and one for sigma. We'll set some weak priors because we don't have any additional information about this simulated data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- brm(\n  formula = DV ~ 0 + Intercept + condition, \n  data = data, \n  family = gaussian(), \n  prior = c(\n    set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n    set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n    set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n  ), \n  sample_prior = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCompiling Stan program...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nTrying to compile a simple C file\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nclang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:88:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL '26506c9e129ffc36bd1658ecb9d890c1' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.066074 seconds (Warm-up)\nChain 1:                0.057278 seconds (Sampling)\nChain 1:                0.123352 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL '26506c9e129ffc36bd1658ecb9d890c1' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.066055 seconds (Warm-up)\nChain 2:                0.066104 seconds (Sampling)\nChain 2:                0.132159 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL '26506c9e129ffc36bd1658ecb9d890c1' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.9e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.06382 seconds (Warm-up)\nChain 3:                0.067943 seconds (Sampling)\nChain 3:                0.131763 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL '26506c9e129ffc36bd1658ecb9d890c1' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.065475 seconds (Warm-up)\nChain 4:                0.063031 seconds (Sampling)\nChain 4:                0.128506 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: DV ~ 0 + Intercept + condition \n   Data: data (Number of observations: 1250) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      0.00      0.06    -0.12     0.12 1.00     1032     1632\nconditionB     0.10      0.09    -0.07     0.27 1.00     1510     2073\nconditionC     0.20      0.09     0.02     0.36 1.00     1514     2436\nconditionD     0.30      0.09     0.13     0.47 1.00     1312     2129\nconditionE     0.40      0.09     0.22     0.57 1.00     1502     2179\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.00      0.02     0.96     1.04 1.00     3775     2982\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThe estimates range, as expected, from 0 for the intercept to 0.40 for condition E.\n\nIf we want pairwise comparisons, we can use the `emmeans` package to obtain them. We use the `emmeans()` function and set the `specs` argument to `pairwise ~ condition`. `pairwise` is a reserved term to use for exactly this purpose. The result is an object that contains estimated marginal means and contrasts. Since we're interested in the pairwise comparisons we only print the contrasts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans <- emmeans(model, specs = pairwise ~ condition)\nemmeans$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast estimate lower.HPD upper.HPD\n A - B     -0.1000    -0.275    0.0668\n A - C     -0.1961    -0.362   -0.0257\n A - D     -0.2941    -0.481   -0.1446\n A - E     -0.3961    -0.578   -0.2250\n B - C     -0.0990    -0.270    0.0713\n B - D     -0.1977    -0.384   -0.0283\n B - E     -0.2967    -0.475   -0.1243\n C - D     -0.0979    -0.273    0.0690\n C - E     -0.1979    -0.377   -0.0314\n D - E     -0.0985    -0.272    0.0758\n\nPoint estimate displayed: median \nHPD interval probability: 0.95 \n```\n:::\n:::\n\n\nThis gives us the estimates as well as lower and upper bounds of a highest probability density intervals. We can also plot them using the following code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts <- as_tibble(emmeans$contrasts)\n\nggplot(contrasts, aes(x = contrast, y = estimate)) +\n  geom_pointrange(aes(ymin = lower.HPD, ymax = upper.HPD)) +\n  labs(x = \"Contrast\", y = \"Estimate with 95% HPD\")\n```\n\n::: {.cell-output-display}\n![Pairwise comparisons via `emmeans`](pairwise-comparisons_files/figure-html/pairwise-comparisons-plot-1.png){width=672}\n:::\n:::\n\n\nAlternatively, we can also calculate specific contrasts using the `hypothesis()` function from `brms`. The added value of calculating contrasts this way is that it also provides us with a Bayes factor if we set priors for all parts of the model.\n\nFor example, we can get the contrast between condition A and B by subtracting the Intercept from the condition B coefficient. We can then get an evidence ratio for the test that this value is larger than 0. This value is simply the ratio of the number of samples larger (or smaller) than a value to the number of samples smaller (or larger) than the value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast_A_B <- hypothesis(model, \"conditionB - Intercept > 0\")\ncontrast_A_B\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionB-Inter... > 0     0.09      0.14    -0.13     0.33          3\n  Post.Prob Star\n1      0.75     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n\n```{.r .cell-code}\n# sum(contrast_A_B$samples$H1 > 0) / sum(contrast_A_B$samples$H1 < 0)\n```\n:::\n\n\nThis gives us an estimate of 0.1 (as expected) and an evidence ratio of 3.004004.\n\nWe can also test whether this contrast is equal to 0. This is a Bayes factor computed via the Savage-Dickey density ratio method. That is, the posterior density at a point of interest is divided by the prior density at the same point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast_A_B_null <- hypothesis(model, \"conditionB - Intercept = 0\")\ncontrast_A_B_null\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionB-Inter... = 0     0.09      0.14    -0.17     0.37       8.52\n  Post.Prob Star\n1       0.9     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n:::\n\n\nThis gives us a Bayes factor of 8.5246971.\n\nAlternatively, we can compare another contrast, say, D vs. B. We can get this contrast by subtracting the coefficient for condition B from the coefficient for condition D.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast_D_B <- hypothesis(model, \"conditionD - conditionB > 0\")\ncontrast_D_B\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionD-condi... > 0      0.2      0.09     0.05     0.35      82.33\n  Post.Prob Star\n1      0.99    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n:::\n\n\nAs expected, we see an estimate of 0.2 (0.4 - 0.2). We also see an evidence ratio of 82.3333333 for the hypothesis that this is larger than 0.\n",
    "supporting": [
      "pairwise-comparisons_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}