<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Factor analysis | Methodology and Statistics</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Factor analysis | Methodology and Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Factor analysis | Methodology and Statistics" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  



<meta name="date" content="2021-11-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="survey-design.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="title">
  <a href="./index.html">Methodology and Statistics</a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>1</b> Factor analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="factor-analysis.html"><a href="factor-analysis.html#exploratory-factor-analyses"><i class="fa fa-check"></i><b>1.1</b> Exploratory factor analyses</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="factor-analysis.html"><a href="factor-analysis.html#sample-size"><i class="fa fa-check"></i><b>1.1.1</b> Sample size</a></li>
<li class="chapter" data-level="1.1.2" data-path="factor-analysis.html"><a href="factor-analysis.html#sampling-adequacy"><i class="fa fa-check"></i><b>1.1.2</b> Sampling Adequacy</a></li>
<li class="chapter" data-level="1.1.3" data-path="factor-analysis.html"><a href="factor-analysis.html#principal-components-vs.-factor-analysis"><i class="fa fa-check"></i><b>1.1.3</b> Principal Components vs. Factor Analysis</a></li>
<li class="chapter" data-level="1.1.4" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-extraction-method"><i class="fa fa-check"></i><b>1.1.4</b> Factor Extraction Method</a></li>
<li class="chapter" data-level="1.1.5" data-path="factor-analysis.html"><a href="factor-analysis.html#number-of-factors-to-retain"><i class="fa fa-check"></i><b>1.1.5</b> Number of factors to retain</a></li>
<li class="chapter" data-level="1.1.6" data-path="factor-analysis.html"><a href="factor-analysis.html#rotation-methods"><i class="fa fa-check"></i><b>1.1.6</b> Rotation methods</a></li>
<li class="chapter" data-level="1.1.7" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-structure"><i class="fa fa-check"></i><b>1.1.7</b> Factor structure</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="factor-analysis.html"><a href="factor-analysis.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>1.2</b> Confirmatory factor analysis</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="factor-analysis.html"><a href="factor-analysis.html#estimator"><i class="fa fa-check"></i><b>1.2.1</b> Estimator</a></li>
<li class="chapter" data-level="1.2.2" data-path="factor-analysis.html"><a href="factor-analysis.html#reliability"><i class="fa fa-check"></i><b>1.2.2</b> Reliability</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="factor-analysis.html"><a href="factor-analysis.html#examples"><i class="fa fa-check"></i><b>1.3</b> Examples</a></li>
<li class="chapter" data-level="1.4" data-path="factor-analysis.html"><a href="factor-analysis.html#r-packages"><i class="fa fa-check"></i><b>1.4</b> R packages</a></li>
<li class="chapter" data-level="1.5" data-path="factor-analysis.html"><a href="factor-analysis.html#useful-links"><i class="fa fa-check"></i><b>1.5</b> Useful links</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="survey-design.html"><a href="survey-design.html"><i class="fa fa-check"></i><b>2</b> Survey design</a>
<ul>
<li class="chapter" data-level="2.1" data-path="survey-design.html"><a href="survey-design.html#number-of-response-options"><i class="fa fa-check"></i><b>2.1</b> Number of response options</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>  
  <a href="https://github.com/rstudio/bookdown" target="blank">
    Published with bookdown
  </a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methodology and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="factor-analysis" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Factor analysis</h1>
<div id="exploratory-factor-analyses" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Exploratory factor analyses</h2>
<p>The goal of an exploratory factor analysis (EFA) is to study the latent factors that underlie responses to a larger number of measures items. It is a popular technique in the development and validation of assessment instruments. Unlike confirmatory factor analysis, EFA is used when there is little or no a priori justification for specifying a particular structural model. This means that the number of underlying factors is determined mostly empirically, rather than theoretically.</p>
<div id="sample-size" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Sample size</h3>
<div id="rules-of-thumb" class="section level4" number="1.1.1.1">
<h4><span class="header-section-number">1.1.1.1</span> Rules of thumb</h4>
<p>The general consensus seems to be that rules of thumb are a bad idea. The reason for that is that these rules only involve one of two factors. Common rules of thumb consist of going for a set number of participants or a particular participant-to-item ratio.</p>
<table>
<caption>Table: Examples of rules of thumb.</caption>
<colgroup>
<col width="35%" />
<col width="22%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Source</th>
<th>Rule</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Participant-only</em></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><span class="citation"><a href="#ref-comrey1992" role="doc-biblioref">Comrey and Lee</a> (<a href="#ref-comrey1992" role="doc-biblioref">1992</a>)</span></td>
<td>50 = very poor<br />
100 = poor<br />
200 = fair<br />
300 = good<br />
500 = very good<br />
1000+ = excellent</td>
</tr>
<tr class="odd">
<td></td>
<td>Cattell (1978)</td>
<td>250</td>
</tr>
<tr class="even">
<td><em>Participant:item ratio</em></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><span class="citation"><a href="#ref-gorsuch2015" role="doc-biblioref">Gorsuch</a> (<a href="#ref-gorsuch2015" role="doc-biblioref">2015</a>)</span></td>
<td>5:1 (100 participants minimum)</td>
</tr>
<tr class="even">
<td></td>
<td><span class="citation"><a href="#ref-everitt1975" role="doc-biblioref">Everitt</a> (<a href="#ref-everitt1975" role="doc-biblioref">1975</a>)</span></td>
<td>10:1 (optimistically)</td>
</tr>
</tbody>
</table>
<p>The reality is that the sample size is dependent on:</p>
<ul>
<li><p>the study design (e.g., cross-sectional vs. longitudinal)</p></li>
<li><p>the size of the relationships among the indicators (e.g., high communalities without cross loadings; strong loadings)</p></li>
<li><p>the reliability of the indicators</p></li>
<li><p>the scaling (e.g., categorical, continuous) and distribution of the indicators</p></li>
<li><p>estimator type (e.g., ML, robust ML, WLSMV)</p></li>
<li><p>the amount and patterns of missing data</p></li>
<li><p>the size of the model (model complexity)</p></li>
</ul>
<p>Costello and Osborne <span class="citation">(<a href="#ref-costello2005" role="doc-biblioref">2005</a>)</span> caution researchers to remember that EFA is a large-sample procedure and that generalizable or replicable results are unlikely if the sample is too small. They found that a ratio of 20:1 produces error rates well above the standard alpha (5%) level.</p>
</div>
</div>
<div id="sampling-adequacy" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Sampling Adequacy</h3>
<p>The Kaiser–Meyer–Olkin (KMO) test is a statistical measure to determine how suited data is for factor analysis. The test measures sampling adequacy for each variable in the model and the complete model. The statistic is a measure of the proportion of variance among variables that might be common variance. The lower the proportion, the higher the KMO value, the more suited the data is to factor analysis</p>
<p>The KMO value ranges from 0 to 1, with 0.60 considered suitable for factor analysis <span class="citation"><a href="#ref-tabachnick2013" role="doc-biblioref">Tabachnick and Fidell</a> (<a href="#ref-tabachnick2013" role="doc-biblioref">2013</a>)</span>. Kaiser himself <span class="citation">(<a href="#ref-kaiser1974" role="doc-biblioref">1974</a>)</span> suggested that KMO &gt; .9 were marvelous, in the .80s, mertitourious, in the .70s, middling, in the .60s, medicore, in the 50s, miserable, and less than .5, unacceptable.</p>
<p>Bartlett’s (1954) test of sphericity is a notoriously sensitive test of the hypothesis that the correlations in a correlation matrix are zero. Because of its sensitivity and its dependence on N, the test is likely to be significant with samples of substantial size even if correlations are very low. Therefore, use of the test is recommended only if there are fewer than, say, five cases per variable <span class="citation">(<a href="#ref-tabachnick2013" role="doc-biblioref">Tabachnick and Fidell 2013</a>)</span>.</p>
</div>
<div id="principal-components-vs.-factor-analysis" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Principal Components vs. Factor Analysis</h3>
<p>Use factor analysis.</p>
<p>The partitioning of variance differentiates a principal components analysis from what we call common factor analysis. Both methods try to reduce the dimensionality of the dataset down to fewer unobserved variables, but whereas PCA assumes that there common variances takes up all of total variance, common factor analysis assumes that total variance can be partitioned into common and unique variance. It is usually more reasonable to assume that you have not measured your set of items perfectly. The unobserved or latent variable that makes up common variance is called a factor, hence the name factor analysis. The other main difference between PCA and factor analysis lies in the goal of your analysis. If your goal is to simply reduce your variable list down into a linear combination of smaller components then PCA is the way to go. However, if you believe there is some latent construct that defines the interrelationship among items, then factor analysis may be more appropriate.</p>
</div>
<div id="factor-extraction-method" class="section level3" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> Factor Extraction Method</h3>
<p>There are multiple factor extract methods, such as:</p>
<ul>
<li><p>minres</p></li>
<li><p>unweighted least squares</p></li>
<li><p>generalized least squares</p></li>
<li><p>maximum likelihood</p></li>
<li><p>principal axis factoring</p></li>
<li><p>alpha factoring</p></li>
<li><p>image factoring.</p></li>
</ul>
<p>Advice is to use the maximum likelihood method if the data is generally normally distributed and to use principal axis factoring if the data is non-normal <span class="citation">(<a href="#ref-costello2005" role="doc-biblioref">Costello and Osborne 2005</a>)</span>.</p>
</div>
<div id="number-of-factors-to-retain" class="section level3" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> Number of factors to retain</h3>
<p>The default in most statistical software packages is to retain all factors with eigenvalues greater than 1. There is broad consensus in the literature that this is among the least accurate methods for selecting the number of factors to retain (Velicer &amp; Jackson, 1990).</p>
<p>Alternate tests for factor retention include the scree test, Velicer’s MAP criteria, and parallel analysis (Velicer &amp; Jackson, 1990).</p>
<p>Zwick and Velicer (1986) tested the scree test, Horn’s parallel test, and Velicer’s MAP test (among others) in simulation studies using a data set with a clear factor structure. Both the parallel test and the minimum average partial test seemed to work well.</p>
</div>
<div id="rotation-methods" class="section level3" number="1.1.6">
<h3><span class="header-section-number">1.1.6</span> Rotation methods</h3>
<p>There are several rotation methods. They can be categorized into one of the categories: orthogonal or oblique.</p>
<p>Orthogonal rotation methods include:</p>
<ul>
<li><p>varimax</p></li>
<li><p>quartimax</p></li>
<li><p>equamax</p></li>
</ul>
<p>Oblique rotation methods include:</p>
<ul>
<li><p>direct oblimin</p></li>
<li><p>quartimin</p></li>
<li><p>promax</p></li>
</ul>
<p>In the social sciences we generally expect some correlation among factors, since behavior is rarely partitioned into neatly packaged units that function independently of one another. Therefore using orthogonal rotation results in a loss of valuable information if the factors are correlated, and oblique rotation should theoretically render a more accurate, and perhaps more reproducible, solution. If the factors are truly uncorrelated, orthogonal and oblique rotation produce nearly identical results. Since oblique rotation will reproduce an orthogonal solution but not vice versa, we recommend oblique rotation.</p>
<p>There is no widely preferred method of oblique rotation; all tend to produce similar results (Fabrigar et al., 1999)</p>
</div>
<div id="factor-structure" class="section level3" number="1.1.7">
<h3><span class="header-section-number">1.1.7</span> Factor structure</h3>
<p>Tabachnick and Fidell (2001) cite .32 as a good rule of thumb for the minimum loading of an item. Others say item loadings above .30 (Costello).</p>
<p>Others say a factor loading coefficient ≥ 0.40 is considered necessary to judge the quality (validity) of an item as an indicator of one factor or another. Some may think that this criterion is quite lax since a factor loading of 0.40 means that only 16% of the explained variance depends on the factor of which one item is the indicator (Gana &amp; Broc)</p>
<p>Some psychometricians (for example, <span class="math display">\[COM 92, TAB 07\]</span>) recommend that we choose items whose R² is greater than 0.40 (thus showing a factorial factor loading greater than 0.63).</p>
<ul>
<li><p>A “crossloading” item is an item that loads at .32 or higher on two or more factors. The researcher needs to decide whether a crossloading item should be dropped from the analysis, which may be a good choice if there are several adequate to strong loaders (.50 or better) on each factor.</p>
<p>A factor with fewer than three items is generally weak and unstable; 5 or more strongly loading items (.50 or better) are desirable and indicate a solid factor.</p></li>
<li><p>, it is important for the latent variable to have at least four indicators (for example: four items). In effect, with only three indicators, the measurement model is just-identified, thus making useless its testability. (Gana &amp; Broc)</p></li>
</ul>
<p>Comrey and Lee (1992) suggest that loadings in excess of .71 (50% overlapping variance) are considered excellent, .63 (40% overlapping variance) very good, .55 (30% overlapping variance) good, .45 (20% overlapping variance) fair, and .32 (10% overlapping variance) poor.</p>
</div>
</div>
<div id="confirmatory-factor-analysis" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Confirmatory factor analysis</h2>
<p>Sample size</p>
<ol style="list-style-type: decimal">
<li>Rules of thumb</li>
<li>Satorra-Saris method</li>
<li>Monte Carlo approach</li>
</ol>
<div id="estimator" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Estimator</h3>
<p>If the data is normally distributed, use the ML estimator.</p>
<p>the findings of Chou and Bentler <span class="math display">\[CHO 95\]</span> make it possible to qualify these remarks. These authors showed that in the presence of a sufficiently large sample, maximum likelihood estimation method and generalized least squares method do not make the results suffer, even when the multivariate normality is slightly violated.</p>
<p>In case of violations, the following estimators can be used:</p>
<ul>
<li><p>MLM</p></li>
<li><p>MLR: Similar to MLM but better suited for small sample sizes (Gana &amp; Broc).</p></li>
<li><p>weighted least squares method (WLS): Requires a large sample size (FLO 04) and frequently runs into convergence issues and improper solutions</p></li>
<li><p>Diagonally Weighted Least Squares (DWLS): For small samples and non-normal data ([JÖR 89)</p></li>
<li><p>WLSM: Robust alternative to DWLS</p></li>
<li><p>WLSMV: Robust alternative to DWLS</p></li>
<li><p>bootstrapping: Not recommended for dichotomous and ordinal measures with few response categories)</p></li>
</ul>
<p>Mardia calculation to determine violations from normal distribution. It can be noted that not only is this standardized coefficient statistically significant, but its value is greater than 5, which is the threshold value beyond which multivariate normality seems to fail <span class="math display">\[KLI 16\]</span>.</p>
<table>
<caption>Recommendations concerning the main estimators available in lavaan according to the type of data (Gana &amp; Broc).</caption>
<colgroup>
<col width="43%" />
<col width="56%" />
</colgroup>
<thead>
<tr class="header">
<th>Data type and normality assumption</th>
<th>Recommended estimator</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Continuous data</td>
<td></td>
</tr>
<tr class="even">
<td>1- Approximately normal distribution</td>
<td>ML</td>
</tr>
<tr class="odd">
<td>2- Violation of normality assumption</td>
<td>ML (in case of moderate violation)</td>
</tr>
<tr class="even">
<td></td>
<td>MLM, MLR, Bootstrap</td>
</tr>
<tr class="odd">
<td>Ordinal/categorical data</td>
<td></td>
</tr>
<tr class="even">
<td>1- Approximately normal distribution</td>
<td>ML (if at least 6 response categories)</td>
</tr>
<tr class="odd">
<td></td>
<td>MLM, MLR (if at least 4 response categories)</td>
</tr>
<tr class="even">
<td></td>
<td>WLSMV (binary response or 3 response categories)</td>
</tr>
<tr class="odd">
<td>2- Violation of normality assumption</td>
<td>ML (if at least 6 response categories)</td>
</tr>
<tr class="even">
<td></td>
<td>MLM, MLR (if at least 4 response categories)</td>
</tr>
<tr class="odd">
<td></td>
<td>WLSMV (in case of severe violation)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="reliability" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Reliability</h3>
<p>Reliability increases the closer the value gets to 1.00, with an acceptability threshold of 0.70.</p>
</div>
</div>
<div id="examples" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Examples</h2>
<ul>
<li>Beyond Sacrificial Harm: A Two-Dimensional Model of Utilitarian Psychology</li>
</ul>
</div>
<div id="r-packages" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> R packages</h2>
<ul>
<li><p>lavaan</p></li>
<li><p>lavaan.survey</p></li>
<li><p>semTools</p></li>
<li><p>semPower</p></li>
</ul>
</div>
<div id="useful-links" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Useful links</h2>
<ul>
<li><a href="https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/" class="uri">https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/</a></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-comrey1992" class="csl-entry">
Comrey, Andrew Laurence, and Howard B. Lee. 1992. <em>A First Course in Factor Analysis</em>. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum Associates.
</div>
<div id="ref-costello2005" class="csl-entry">
Costello, Anna, and Jason Osborne. 2005. <span>“Best Practices in Exploratory Factor Analysis: Four Recommendations for Getting the Most from Your Analysis.”</span> <em>Practical Assessment, Research, and Evaluation</em> 10 (1). <a href="https://doi.org/10.7275/jyj1-4868">https://doi.org/10.7275/jyj1-4868</a>.
</div>
<div id="ref-everitt1975" class="csl-entry">
Everitt, B. S. 1975. <span>“Multivariate Analysis: The Need for Data, and Other Problems.”</span> <em>British Journal of Psychiatry</em> 126 (3): 237–40. <a href="https://doi.org/10.1192/bjp.126.3.237">https://doi.org/10.1192/bjp.126.3.237</a>.
</div>
<div id="ref-gorsuch2015" class="csl-entry">
Gorsuch, Richard L. 2015. <em>Factor Analysis</em>. Classic. New York, NY: Routledge.
</div>
<div id="ref-kaiser1974" class="csl-entry">
Kaiser, Henry F. 1974. <span>“An Index of Factorial Simplicity.”</span> <em>Psychometrika</em> 39 (1): 31–36. <a href="https://doi.org/10.1007/BF02291575">https://doi.org/10.1007/BF02291575</a>.
</div>
<div id="ref-tabachnick2013" class="csl-entry">
Tabachnick, Barbara G., and Linda S. Fidell. 2013. <em>Using Multivariate Statistics</em>. Sixth. <span>Boston</span>: <span>Pearson</span>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="survey-design.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-factor-analysis.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
