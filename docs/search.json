[
  {
    "objectID": "index.html#word-of-caution",
    "href": "index.html#word-of-caution",
    "title": "How to Science",
    "section": "Word of Caution",
    "text": "Word of Caution\nSome sections in the book are not yet finished. They’re work in progress. Sometimes I think they’re already a bit useful, so I make them public. If I think they’re not finished/polished yet, I put a warning at the start of the page to indicate that.\nHaving said that, this website will forever be a work in progress because the content is about current best practices. As best practices are likely to change over time, so the content of this website will change with it. If I realize that something is heavily outdated, I will make a note of it.\nIt’s also very likely that there are mistakes. These mistakes can theoretically range from gross errors to simple typos, or a reliance on outdated information. If you find a mistake, please contact me or click on the GitHub link on each page and create an Issue."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "How to Science",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe following people have contributed to this book:\n\nWillem Sleegers\n\nIf I’ve missed your contributions and you deserve to be on this list, please don’t hesitate to contact me or add yourself via a Pull Request on GitHub!"
  },
  {
    "objectID": "content/methodology/constructs/risk.html",
    "href": "content/methodology/constructs/risk.html",
    "title": "Risk Attitudes",
    "section": "",
    "text": "Dohmen et al. (2011) asked respondents about their risk attitude with a single item.\n\nHow do you see yourself: are you generally a person who is fully prepared to take risks or do you try to avoid taking risks?\n\nThey found decently sized correlations with decisions in a lottery experiment and domain-specific risk attitudes. They also found it could predict risky behaviors such as holding stocks, driving a car, doing sports, being self-employed, and smoking.\nNotably, they find that the general measure is a good predictor, but that context-specific measures of risk are more powerful predictors of risk in the same context.\n\n\n\n\nReferences\n\nDohmen, T., Falk, A., Huffman, D., Sunde, U., Schupp, J., & Wagner, G. G. (2011). Individual risk attitudes: Measurement, determinants, and behavioral consequences. Journal of the European Economic Association, 9(3), 522–550. https://doi.org/10.1111/j.1542-4774.2011.01015.x",
    "crumbs": [
      "Risk Attitudes"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/item-development.html",
    "href": "content/methodology/survey-design/item-development.html",
    "title": "Item Development",
    "section": "",
    "text": "This step is an important step in the development of a scale as serious problems with the item pool will reverberate through all subsequent data analyses and scale construction efforts.\nitems should be written that are (i) relevant to the constructs to be measured, and (ii) representative of all potentially important aspects of the target construct. Having formal construct definitions is particularly important here, as such definitions should guide the item writing process.\nBesides including items to cover all the different facets of a particular construct, it’s also important that the item pool includes items reflecting all levels of the construct.\nItem writing guidelines (Simms, 2008):",
    "crumbs": [
      "Survey Design",
      "Item Development"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/item-development.html#pilot-testing",
    "href": "content/methodology/survey-design/item-development.html#pilot-testing",
    "title": "Item Development",
    "section": "Pilot testing",
    "text": "Pilot testing\nAfter the initial item pool is complete, it makes sense to pilot test the items before running a large-scaled exploratory study.\nFactor loadings can be improved by using multiple response (Likert-type) items, as they generally result in higher loadings than two-choice items (Comrey & Montag, 1982; Oswald & Velicer, 1980; Velicer, DiClemente, & Corriveau, 1984; Velicer, Govia, Cherico, & Corriveau, 1985; Velicer & Stevenson, 1978). Likewise, the quality of item writing can affect the size of the loadings, that is, the expression of an item in simple language, restricting the item to a single idea, or using content that is appropriate to a majority of respondents are all ways of improving items.",
    "crumbs": [
      "Survey Design",
      "Item Development"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/data-quality-checks.html",
    "href": "content/methodology/survey-design/data-quality-checks.html",
    "title": "Data quality checks",
    "section": "",
    "text": "Unfortunately, not all respondents pay careful attention to survey instructions and survey items. We therefore would like to be able to detect these participants and prevent them from participating in the survey or exclude them from data analysis.\nSome survey platforms have rules about what kind of checks they allow. Prolific is one of them. Make sure to follow the link to check their rules so you don’t break them.\nThere are different types of checks to detect inattentive participants: attention checks, comprehension checks, and commitment checks.",
    "crumbs": [
      "Survey Design",
      "Data quality checks"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/data-quality-checks.html#attention-checks",
    "href": "content/methodology/survey-design/data-quality-checks.html#attention-checks",
    "title": "Data quality checks",
    "section": "Attention checks",
    "text": "Attention checks\nAttention checks are defined as simple ways to determine who is paying attention to your study instructions, and the amount of effort participants devote to reading questions before answering them (Oppenheimer et al., 2009).\n\nInstructional Manipulation Checks (IMCs)\nInstructional manipulation checks (IMCs) explicitly instruct a participant to complete a task in a certain way, and are therefore designed to see whether or not a participant has paid attention to the question being asked.\nIMCs can be used in different formats (e.g., multiple-choice, text-based). Each format has advantages and disadvantages. Multiple-choice formats can be answered correctly randomly but text-based answers may be more difficult to analyze.\n\nExamples\n\nBinary\n\nPlease select ‘True’ for this question. [True, False]\n\n\n\nMultiple-choice\n\nThe color test you are about to take part in is very simple, when asked for your favorite color you must select ‘Green’. This is an attention check. Based on the text you read above, what color have you been asked to enter? [Red, Blue, Green, Organce, Brown] (Prolific’s Attention and Comprehension Check Policy, 2024)\nFor this question, please select ‘Somewhat Agree’ as your answer. [Strongly disagree, Disagree, Somewhat disagree, Somewhat agree, Agree, Strongly agree]\nThis is a simple question. You don’t need to be a wine connoisseur or avid beer drinker to answer. When asked for your favorite drink, you need to select carrot juice. Based on the text above, what is your favorite drink? [Wine; Beer; Vodka; Whiskey; Carrot juice; Other]\nHelp us keep track of who is paying attention. Please select “Somewhat disagree” from the options below. [Multiple choice: Strongly agree - Strongly disagree] (Stagnaro et al., 2024)\nPlease ignore this question and do not answer. [choose all that apply: Strongly agree Strongly disagree] (Stagnaro et al., 2024)\n\n\n\nText-based\n\nIn the box below, please type the word ‘Survey’ to indicate you are paying attention.\nPlease enter the number ‘5’ in the box below.\nThe following is to verify that you are a real person. Please enter the word “purple” in the box below. (Geisen, 2022)\nPlease write “twenty-five” using numbers. (Stagnaro et al., 2024)\n\n\n\nSlider\n\nPlease position the slider to the number 5.\n\n\n\n\n\nNonsensical Items\nNonsensical item checks embed a nonsensical item within a survey, to which only one or two responses to the question’s options can be justified as objectively correct.\n\nExamples\n\nI swim across the Atlanic Ocean to get to work every day. [Strongly disagree, Disagree, Agree, Strongly agree] (Prolific’s Attention and Comprehension Check Policy, 2024)\nI work fourteen months in a year. [Yes, this is true of me; No, this is not true of me]\nI have never used a computer. [Yes, this is true of me; No, this is not true of me]\nWhat type of social media accounts do you use (if any)? Please answer honestly. [do they select the option “TisFask” which does not exist nor sound like any social media option] (Stagnaro et al., 2024)\nWhile watching the television, have you ever had a fatal heart attack? [6-point Likert ranging from “Never” to “Often”] (Paolacci et al., 2010)\nAre you licensed to operate a class SSGN submarine? [Yes/No] (Kennedy, 2022)\n\n\n\n\nFactual or logical questions\nFactual or logical questions consist of asking a question with a correct answer that everyone is likely to know.\n\nExamples\n\nWhat is 2 + 2? [Text box]\nWhich of the following is a primary color? [Green, Orange, Blue]\nIf yesterday was Monday, what is today? [Text box]\nWhich of these is a vegetable? [Egg, Salmon, Broccoli, Cheeseburger, Pizza, Milk] (Geisen, 2022)\nWhich of the following words is most closely associated with ‘book’? [Pen; Saw; Car; Pants; House]",
    "crumbs": [
      "Survey Design",
      "Data quality checks"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/data-quality-checks.html#comprehension-checks",
    "href": "content/methodology/survey-design/data-quality-checks.html#comprehension-checks",
    "title": "Data quality checks",
    "section": "Comprehension checks",
    "text": "Comprehension checks\nComprehension checks are used to measure participant’s level of understanding of specific study instructions to ensure that they understand what is required of them",
    "crumbs": [
      "Survey Design",
      "Data quality checks"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/data-quality-checks.html#commitment-checks",
    "href": "content/methodology/survey-design/data-quality-checks.html#commitment-checks",
    "title": "Data quality checks",
    "section": "Commitment checks",
    "text": "Commitment checks\nCommitment checks can be used to measure whether participants are motivated to answer questions and answer them honestly.\n\nExamples\n\nWe care about the quality of our survey data. For us to get the most accurate measures of your opinions, it is important that you provide thoughtful answers to each question in this survey. Do you commit to providing thoughtful answers to the questions in this survey? [I can’t promise either way; Yes, I will; No, I will not] (Geisen, 2022)",
    "crumbs": [
      "Survey Design",
      "Data quality checks"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/data-quality-checks.html#survey-platform-rules",
    "href": "content/methodology/survey-design/data-quality-checks.html#survey-platform-rules",
    "title": "Data quality checks",
    "section": "Survey platform rules",
    "text": "Survey platform rules\nSome survey platforms have rules about what kind of checks they allow. Prolific is one of them. Make sure to follow the link to check their rules so you don’t break them.",
    "crumbs": [
      "Survey Design",
      "Data quality checks"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/recommended-reading.html",
    "href": "content/methodology/survey-design/recommended-reading.html",
    "title": "Recommended Reading",
    "section": "",
    "text": "The following papers are useful overview or review papers that are, in my mind, particular useful to read:\n\n\n\n\nReferences\n\nGehlbach, H., & Brinkworth, M. E. (2011). Measure twice, cut down error: A process for enhancing the validity of survey scales. Review of General Psychology, 15(4), 380–387. https://doi.org/10.1037/a0025704\n\n\nWolf, M. G., Ihm, E., Maul, A., & Taves, A. (2019). Survey item validation. https://doi.org/10.31234/osf.io/k27w3",
    "crumbs": [
      "Survey Design",
      "Recommended Reading"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html",
    "title": "BFI-2-XS",
    "section": "",
    "text": "The BFI-2-XS is a 15-item extra-short form, of the BFI-2. It is are appropriate for research contexts in which, due to pressing concerns about assessment time or respondent fatigue, administering the full BFI-2 would not be feasible. For most studies, however, it is recommended to administer the full measure due to its greater reliability and validity.",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#items",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#items",
    "title": "BFI-2-XS",
    "section": "Items",
    "text": "Items\n\nI am someone who tends to be quiet.\nI am someone who is compassionate, has a soft heart.\nI am someone who tends to be disorganized.\nI am someone who worries a lot.\nI am someone who is fascinated by art, music, or literature.\nI am someone who is dominant, acts as a leader.\nI am someone who is sometimes rude to others.\nI am someone who has difficulty getting started on tasks.\nI am someone who tends to feel depressed, blue.\nI am someone who has little interest in abstract ideas.\nI am someone who is full of energy.\nI am someone who assumes the best about people.\nI am someone who is reliable, can always be counted on.\nI am someone who is emotionally stable, not easily upset.\nI am someone who is original, comes up with new ideas.",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#instructions",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#instructions",
    "title": "BFI-2-XS",
    "section": "Instructions",
    "text": "Instructions\n\nHere are a number of characteristics that may or may not apply to you. For example, do you agree that you are someone who likes to spend time with others? Please write a number next to each statement to indicate the extent to which you agree or disagree with that statement.",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#response-options",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#response-options",
    "title": "BFI-2-XS",
    "section": "Response options",
    "text": "Response options\n\nDisagree strongly\nDisagree a little\nNeutral; no opinion\nAgree a little\nAgree strongly",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#download",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#download",
    "title": "BFI-2-XS",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#extra",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#extra",
    "title": "BFI-2-XS",
    "section": "Extra",
    "text": "Extra\nSee also this link for more information, such as versions of different lengths and translations.",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#reference",
    "href": "content/materials/scales/BFI-2-XS/BFI-2-XS.html#reference",
    "title": "BFI-2-XS",
    "section": "Reference",
    "text": "Reference\n\n\nSoto, C. J., & John, O. P. (2017). Short and extra-short forms of the Big Five Inventory2: The BFI-2-S and BFI-2-XS. Journal of Research in Personality, 68, 69–81. https://doi.org/10.1016/j.jrp.2017.02.004",
    "crumbs": [
      "Personality",
      "BFI-2-XS"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html",
    "href": "content/materials/scales/TIPI/TIPI.html",
    "title": "TIPI",
    "section": "",
    "text": "The TIPI is a 10-item measure of the Big Five (or Five-Factor Model) dimensions.",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html#items",
    "href": "content/materials/scales/TIPI/TIPI.html#items",
    "title": "TIPI",
    "section": "Items",
    "text": "Items\n\nI see myself as extraverted, enthusiastic.\nI see myself as critical, quarrelsome.\nI see myself as dependable, self-disciplined.\nI see myself as anxious, easily upset.\nI see myself as open to new experiences, complex.\nI see myself as reserved, quiet.\nI see myself as sympathetic, warm.\nI see myself as disorganized, careless.\nI see myself as calm, emotionally stable.\nI see myself as conventional, uncreative.",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html#instructions",
    "href": "content/materials/scales/TIPI/TIPI.html#instructions",
    "title": "TIPI",
    "section": "Instructions",
    "text": "Instructions\n\nHere are a number of personality traits that may or may not apply to you. Please write a number next to each statement to indicate the extent to which you agree or disagree with that statement. You should rate the extent to which the pair of traits applies to you, even if one characteristic applies more strongly than the other.",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html#response-options",
    "href": "content/materials/scales/TIPI/TIPI.html#response-options",
    "title": "TIPI",
    "section": "Response options",
    "text": "Response options\n\nDisagree strongly\nDisagree moderately\nDisagree a little\nNeither agree nor disagree\nAgree a little\nAgree moderately\nAgree strongly",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html#download",
    "href": "content/materials/scales/TIPI/TIPI.html#download",
    "title": "TIPI",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/TIPI/TIPI.html#reference",
    "href": "content/materials/scales/TIPI/TIPI.html#reference",
    "title": "TIPI",
    "section": "Reference",
    "text": "Reference\n\n\nGosling, S. D., Rentfrow, P. J., & Swann, W. B. (2003). A very brief measure of the Big-Five personality domains. Journal of Research in Personality, 37(6), 504–528. https://doi.org/10.1016/S0092-6566(03)00046-1",
    "crumbs": [
      "Personality",
      "TIPI"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html",
    "href": "content/materials/scales/AAS/AAS.html",
    "title": "Animal Attitude Scale",
    "section": "",
    "text": "The Animal Attitudes Scale is a 20-item measure of pro-animal welfare attitudes. Two short versions of the scale are available (a 5 and a 10 item version).",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html#items",
    "href": "content/materials/scales/AAS/AAS.html#items",
    "title": "Animal Attitude Scale",
    "section": "Items",
    "text": "Items\n\nIt is morally wrong to hunt wild animals just for sport.\nI do not think that there is anything wrong with using animals in medical research.\nThere should be extremely stiff penalties including jail sentences for people who participate in cock fighting.\nWild animals, such as mink and raccoons, should not be trapped and their skins made into fur coats.\nThere is nothing morally wrong with hunting wild animals for food.\nI think people who object to raising animals for meat are too sentimental.\nMuch of the scientific research done with animals is unnecessary and cruel.\nI think it is perfectly acceptable for cattle and hogs to be raised for human consumption.\nBasically, humans have the right to use animals as we see fit.\nThe slaughter of whales and dolphins should be immediately stopped even if it means some people will be put out of work.\nI sometimes get upset when I see wild animals in cages at zoos.\nIn general, I think that human economic gain is more important than setting aside more land for wildlife.\nToo much fuss is made over the welfare of animals these days when there are many human problems that need to be solved.\nBreeding animals for their skins is a legitimate use of animals.\nSome aspects of biology can only be learned through dissecting preserved animals such as cats.\nContinued research with animals will be necessary if we are to ever conquer diseases such as cancer, heart disease, and AIDS.\nIt is unethical to breed purebred dogs for pets when millions of dogs are killed in animal shelters each year.\nThe production of inexpensive meat, eggs, and dairy products justifies maintaining animals under crowded conditions.\nThe use of animals such as rabbits for testing the safety of cosmetics and household products is unnecessary and should be stopped.\nThe use of animals in rodeos and circuses is cruel.",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html#instructions",
    "href": "content/materials/scales/AAS/AAS.html#instructions",
    "title": "Animal Attitude Scale",
    "section": "Instructions",
    "text": "Instructions\n\nListed below are 20 statements regarding the use of animals. Circle the letters that indicate the extent to which you agree or disagree with the statement.",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html#response-options",
    "href": "content/materials/scales/AAS/AAS.html#response-options",
    "title": "Animal Attitude Scale",
    "section": "Response options",
    "text": "Response options\n\nStrongly disagree\nDisagree\nUndecided\nAgree\nStrongly agree",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html#download",
    "href": "content/materials/scales/AAS/AAS.html#download",
    "title": "Animal Attitude Scale",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/AAS/AAS.html#reference",
    "href": "content/materials/scales/AAS/AAS.html#reference",
    "title": "Animal Attitude Scale",
    "section": "Reference",
    "text": "Reference\n\n\nHerzog, H. A., Betchart, N. S., & Pittman, R. B. (1991). Gender, sex role orientation, and attitudes toward animals. Anthrozoös, 4(3), 184–191. https://doi.org/10.2752/089279391787057170\n\n\nHerzog, H., Grayson, S., & McCord, D. (2015). Brief measures of the Animal Attitude Scale. Anthrozoös, 28(1), 145–152. https://doi.org/10.2752/089279315X14129350721894",
    "crumbs": [
      "Animals",
      "Animal Attitude Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/SOP2/SOP2.html",
    "href": "content/materials/scales/SOP2/SOP2.html",
    "title": "The Optimism–Pessimism Short Scale–2",
    "section": "",
    "text": "The Optimism–Pessimism Short Scale–2 (SOP2) is a 2-item measure of optimism—the tendency to look to the future with confidence and mostly expect good things to happen, rather than to look at the future full of doubt and mostly expect bad things to happen.",
    "crumbs": [
      "Personality",
      "The Optimism–Pessimism Short Scale–2"
    ]
  },
  {
    "objectID": "content/materials/scales/SOP2/SOP2.html#items",
    "href": "content/materials/scales/SOP2/SOP2.html#items",
    "title": "The Optimism–Pessimism Short Scale–2",
    "section": "Items",
    "text": "Items\n\nThe next question deals with optimism. Optimists are people who look to the future with confidence and who mostly expect good things to happen. How would you describe yourself? How optimistic are you in general?\nThe next question is about pessimism. Pessimists are people who are full of doubt when they look to the future and who mostly expect bad things to happen. How would you describe yourself? How pessimistic are you in general?",
    "crumbs": [
      "Personality",
      "The Optimism–Pessimism Short Scale–2"
    ]
  },
  {
    "objectID": "content/materials/scales/SOP2/SOP2.html#response-options",
    "href": "content/materials/scales/SOP2/SOP2.html#response-options",
    "title": "The Optimism–Pessimism Short Scale–2",
    "section": "Response options",
    "text": "Response options\nEach question is rated on a 7-point scale, but only the first and last option is labelled.\nFor the optimism item:\n\nnot at all optimistic\nvery optimistic\n\nFor the pessimism item:\n\nnot at all pessimistic\nvery pessimistic",
    "crumbs": [
      "Personality",
      "The Optimism–Pessimism Short Scale–2"
    ]
  },
  {
    "objectID": "content/materials/scales/SOP2/SOP2.html#download",
    "href": "content/materials/scales/SOP2/SOP2.html#download",
    "title": "The Optimism–Pessimism Short Scale–2",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Personality",
      "The Optimism–Pessimism Short Scale–2"
    ]
  },
  {
    "objectID": "content/materials/scales/SOP2/SOP2.html#reference",
    "href": "content/materials/scales/SOP2/SOP2.html#reference",
    "title": "The Optimism–Pessimism Short Scale–2",
    "section": "Reference",
    "text": "Reference\n\n\nNießen, D., Groskurth, K., Kemper, C. J., Rammstedt, B., & Lechner, C. M. (2022). The OptimismPessimism Short Scale2 (SOP2): A comprehensive validation of the English-language adaptation. Measurement Instruments for the Social Sciences, 4(1), 1. https://doi.org/10.1186/s42409-021-00027-6",
    "crumbs": [
      "Personality",
      "The Optimism–Pessimism Short Scale–2"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/pairwise-comparisons.html",
    "href": "content/statistics/group-differences/pairwise-comparisons.html",
    "title": "Pairwise comparisons",
    "section": "",
    "text": "# Load packages\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(brms)\nlibrary(emmeans)\n\n# Set the default ggplot theme\ntheme_set(theme_minimal())\nThis section is about different statistical techniques to analyze group differences.",
    "crumbs": [
      "Pairwise comparisons"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/pairwise-comparisons.html#bayesian",
    "href": "content/statistics/group-differences/pairwise-comparisons.html#bayesian",
    "title": "Pairwise comparisons",
    "section": "Bayesian",
    "text": "Bayesian\n\nPairwise comparisons\nIn this scenario we simulate data from a study with 5 different groups. The conditions differ from each by a small amount and for simplicity’s sake each condition has a standard deviation of 1. The sample size per condition is 250.\n\n# Set the simulation parameters\nMs &lt;- c(0, 0.1, 0.2, 0.3, 0.4)\nSDs &lt;- 1\nn &lt;- 250\n\n# Produce the variance-covariance matrix\nSigma &lt;- matrix(\n  nrow = length(Ms), \n  ncol = length(Ms), \n  data = c(\n    SDs^2, 0, 0, 0, 0,\n    0, SDs^2, 0, 0, 0,\n    0, 0, SDs^2, 0, 0,\n    0, 0, 0, SDs^2, 0,\n    0, 0, 0, 0, SDs^2\n  )\n)\n\n# Simulate the values\nm &lt;- mvrnorm(n = n, mu = Ms, Sigma = Sigma, empirical = TRUE)\n\n# Prepare the data by converting it to a data frame and making it tidy\ncolnames(m) &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\")\n\ndata &lt;- as_tibble(m)\n\ndata &lt;- pivot_longer(\n  data = data, \n  cols = everything(), \n  names_to = \"condition\", \n  values_to = \"DV\"\n)\n\ndata &lt;- mutate(data, id = 1:n(), .before = condition)\n\nTo perform the pairwise comparisons we first fit a model with brms. If we also want to calculate Bayes factors, we need to set a prior for the intercept. For technical reasons, this needs to be done by explicitly including the intercept in the formula. After that we need to set 3 priors: 1 for the intercept, 1 for all the other coefficients, and one for sigma. We’ll set some weak priors because we don’t have any additional information about this simulated data.\n\nmodel &lt;- brm(\n  formula = DV ~ 0 + Intercept + condition, \n  data = data, \n  family = gaussian(), \n  prior = c(\n    set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n    set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n    set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n  ), \n  sample_prior = TRUE\n)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'fccf7c9febbc328167e179f62cd6df23' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.070093 seconds (Warm-up)\nChain 1:                0.07575 seconds (Sampling)\nChain 1:                0.145843 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'fccf7c9febbc328167e179f62cd6df23' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.073741 seconds (Warm-up)\nChain 2:                0.078186 seconds (Sampling)\nChain 2:                0.151927 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'fccf7c9febbc328167e179f62cd6df23' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.071493 seconds (Warm-up)\nChain 3:                0.066388 seconds (Sampling)\nChain 3:                0.137881 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'fccf7c9febbc328167e179f62cd6df23' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.073044 seconds (Warm-up)\nChain 4:                0.074436 seconds (Sampling)\nChain 4:                0.14748 seconds (Total)\nChain 4: \n\nmodel\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: DV ~ 0 + Intercept + condition \n   Data: data (Number of observations: 1250) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      0.01      0.06    -0.12     0.14 1.00     1339     1815\nconditionB     0.09      0.09    -0.09     0.26 1.00     1807     2047\nconditionC     0.19      0.09     0.01     0.37 1.00     1725     1829\nconditionD     0.29      0.09     0.11     0.46 1.00     1726     2200\nconditionE     0.39      0.09     0.21     0.57 1.00     1750     2030\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.00      0.02     0.96     1.04 1.00     2830     2528\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe estimates range, as expected, from 0 for the intercept to 0.40 for condition E.\nIf we want pairwise comparisons, we can use the emmeans package to obtain them. We use the emmeans() function and set the specs argument to pairwise ~ condition. pairwise is a reserved term to use for exactly this purpose. The result is an object that contains estimated marginal means and contrasts. Since we’re interested in the pairwise comparisons we only print the contrasts.\n\nemmeans &lt;- emmeans(model, specs = pairwise ~ condition)\n\ncontrasts &lt;- emmeans$contrasts\ncontrasts\n\n contrast estimate lower.HPD upper.HPD\n A - B     -0.0910    -0.273    0.0744\n A - C     -0.1898    -0.372   -0.0160\n A - D     -0.2908    -0.468   -0.1208\n A - E     -0.3904    -0.559   -0.2083\n B - C     -0.1003    -0.273    0.0719\n B - D     -0.1995    -0.363   -0.0139\n B - E     -0.2991    -0.461   -0.1189\n C - D     -0.0996    -0.280    0.0668\n C - E     -0.2005    -0.378   -0.0227\n D - E     -0.1002    -0.278    0.0782\n\nPoint estimate displayed: median \nHPD interval probability: 0.95 \n\n\nThis gives us the estimates as well as lower and upper bounds of a highest probability density intervals. We can also plot them using the following code.\n\ncontrasts &lt;- as_tibble(contrasts)\n\nggplot(contrasts, aes(x = contrast, y = estimate)) +\n  geom_pointrange(aes(ymin = lower.HPD, ymax = upper.HPD)) +\n  labs(x = \"Contrast\", y = \"Estimate with 95% HPD\")\n\n\n\n\nPairwise comparisons via emmeans\n\n\n\n\nAlternatively, we can also calculate specific contrasts using the hypothesis() function from brms. The added value of calculating contrasts this way is that it also provides us with a Bayes factor if we set priors for all parts of the model.\nFor example, we can get the contrast between condition A and B by subtracting the Intercept from the condition B coefficient. We can then get an evidence ratio for the test that this value is larger than 0. This value is simply the ratio of the number of samples larger (or smaller) than a value to the number of samples smaller (or larger) than the value.\n\ncontrast_A_B &lt;- hypothesis(model, \"conditionB - Intercept &gt; 0\")\ncontrast_A_B\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionB-Inter... &gt; 0     0.08      0.14    -0.15     0.32       2.85\n  Post.Prob Star\n1      0.74     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n# sum(contrast_A_B$samples$H1 &gt; 0) / sum(contrast_A_B$samples$H1 &lt; 0)\n\nThis gives us an estimate of 0.1 (as expected) and an evidence ratio of 2.8461538.\nWe can also test whether this contrast is equal to 0. This is a Bayes factor computed via the Savage-Dickey density ratio method. That is, the posterior density at a point of interest is divided by the prior density at the same point.\n\ncontrast_A_B_null &lt;- hypothesis(model, \"conditionB - Intercept = 0\")\ncontrast_A_B_null\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionB-Inter... = 0     0.08      0.14     -0.2     0.36       8.56\n  Post.Prob Star\n1       0.9     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\nThis gives us a Bayes factor of 8.5605476.\nAlternatively, we can compare another contrast, say, D vs. B. We can get this contrast by subtracting the coefficient for condition B from the coefficient for condition D.\n\ncontrast_D_B &lt;- hypothesis(model, \"conditionD - conditionB &gt; 0\")\ncontrast_D_B\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (conditionD-condi... &gt; 0      0.2      0.09     0.06     0.34      70.43\n  Post.Prob Star\n1      0.99    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\nAs expected, we see an estimate of 0.2 (0.4 - 0.2). We also see an evidence ratio of 70.4285714 for the hypothesis that this is larger than 0.",
    "crumbs": [
      "Pairwise comparisons"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/confidence-intervals.html",
    "href": "content/statistics/group-differences/confidence-intervals.html",
    "title": "Confidence intervals",
    "section": "",
    "text": "Code\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(lmerTest)\nlibrary(marginaleffects)\n\ntheme_set(theme_minimal())\n\nset.seed(1)",
    "crumbs": [
      "Confidence intervals"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/confidence-intervals.html#groups",
    "href": "content/statistics/group-differences/confidence-intervals.html#groups",
    "title": "Confidence intervals",
    "section": "4 groups",
    "text": "4 groups\n\n\nCode\n# Set the simulation parameters\nMs &lt;- c(3, 3.2, 3.5, 3.8)\nSDs &lt;- c(1, 1, 1, 1)\nlabels &lt;- c(\"A\", \"B\", \"C\", \"D\")\n\n# Produce the variance-covariance matrix\nSigma &lt;- matrix(\n  nrow = length(Ms),\n  ncol = length(Ms),\n  data = diag(SDs)\n)\n\npreds &lt;- tibble()\nNs &lt;- c(20, 50, 100, 200, 300, 400)\n\n# Simulate\nfor (n in Ns) {\n  m &lt;- mvrnorm(n = n, mu = Ms, Sigma = Sigma, empirical = TRUE)\n\n  colnames(m) &lt;- labels\n\n  data &lt;- m |&gt;\n    as_tibble() |&gt;\n    pivot_longer(\n      cols = everything(),\n      names_to = \"predictor\",\n      values_to = \"response\"\n    )\n\n  mod &lt;- lm(response ~ predictor, data = data)\n\n  preds &lt;- mod |&gt;\n    avg_predictions(variables = \"predictor\") |&gt;\n    as_tibble() |&gt;\n    mutate(n = n) |&gt;\n    bind_rows(preds)\n\n  temp1 &lt;- avg_comparisons(mod)\n}\n\nggplot(preds, aes(x = predictor, y = estimate)) +\n  geom_point(position = position_dodge(.9)) +\n  geom_rect(\n    aes(\n      ymin = conf.low, ymax = conf.high,\n      xmin = 0, xmax = 4,\n      group = predictor\n    ),\n    alpha = .25\n  ) +\n  geom_errorbar(\n    aes(ymin = conf.low, ymax = conf.high),\n    width = .2, position = position_dodge(.9)\n  ) +\n  facet_wrap(\n    ~n, \n    ncol = 2, \n    labeller = labeller(n = function(x) paste(\"n = \", x))\n  ) +\n  labs(\n    x = \"Group\",\n    y = \"Predicted average\"\n  ) +\n  scale_y_continuous(limits = c(1, 5), breaks = 1:5)",
    "crumbs": [
      "Confidence intervals"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-recommended-reading.html",
    "href": "content/statistics/factor-analysis/EFA/EFA-recommended-reading.html",
    "title": "Recommend reading",
    "section": "",
    "text": "I found the following best practices papers useful:\n\nEvaluating the use of exploratory factor analysis in psychological research by @fabrigar1999\nIn search of underlying dimensions: The use (and abuse) of factor analysis in personality and social psychology bulletin by @russell2002\nBest practices in exploratory factor analysis by @osborne2014",
    "crumbs": [
      "Exploratory factor analysis",
      "Recommend reading"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-recommended-reading.html#recommended-reading",
    "href": "content/statistics/factor-analysis/EFA/EFA-recommended-reading.html#recommended-reading",
    "title": "Recommend reading",
    "section": "",
    "text": "I found the following best practices papers useful:\n\nEvaluating the use of exploratory factor analysis in psychological research by @fabrigar1999\nIn search of underlying dimensions: The use (and abuse) of factor analysis in personality and social psychology bulletin by @russell2002\nBest practices in exploratory factor analysis by @osborne2014",
    "crumbs": [
      "Exploratory factor analysis",
      "Recommend reading"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-glossary.html",
    "href": "content/statistics/factor-analysis/EFA/EFA-glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Glossary\n\ncommunality\nThe amount of variance in the item/variable explained by the (retained) factors. It is the sum of the squared loadings.\n\n\neigenvalue\nThe amount of variance explained by a factor; the sum of squared factor loadings.\n\n\nh2\nSee communality.\n\n\nu2\n1 - h2. residual variance, a.k.a. uniqueness",
    "crumbs": [
      "Exploratory factor analysis",
      "Glossary"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html",
    "title": "Best practices in CFA",
    "section": "",
    "text": "Warning\n\n\n\nThis chapter is still a work in progress.\nConfirmatory factor analysis (CFA) is used to specify a particular structural model. In the context of a factor analysis, that means you have a clear theoretical and/or empirical basis about the number of factors and which items should load on which factor. In this case, CFA is more appropriate than an exploratory factor analysis (EFA because it allows you to test how well your model fit the data.",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#sample-size",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#sample-size",
    "title": "Best practices in CFA",
    "section": "Sample size",
    "text": "Sample size\nFor confirmatory factor analyses there are several ways to determine the appropriate sample size, including:\n\nRules of thumb\nMonte Carlo simulation\nThe Satorra-Saris method\nThe RMSEA method\n\n\nRules of thumb\nJust like with EFA, there are many rules of thumb for the sample size of a CFA. However, just like with EFA, these are gross oversimplifications and might easily provide a misleading estimate. Rules of thumb usually consist of only a fixed sample size (e.g., use N = 300) or a sample size ratio (e.g., n = 5-10 per estimated parameter). In reality, the sample size depends on many more factors, including the type of model and the goal of the researcher (e.g., powering for overall misfit or a specific parameter).\nConclusion: Try to avoid relying on rules of thumb\n\n\nMonte Carlo method\nThe Monte Carlo method is a simulation-based method to obtain the sample size for a given model and statistical test. It works by generating a large number of data sets from a population model, fitting the model to each data set, storing the target statistic, and calculating the proportion of data sets for which the statistic of interest (e.g., \\(χ^2\\) value, fit statistic, regression coefficient) is statistically significant. This proportion is the statistical power for the statistical test.\nThis method is probably the most difficult of the methods because it requires being able to simulate the population data. Depending on which analysis you will run on each data set, this method may also take a lot of time. It is, however, the most flexible method and can tell you the power for the exact test you want to run, whether that’s a commonly-used fit statistic or something else (e.g., confidence interval range, multiple parameters being significant).\nIn the context of a factor analysis, this method is difficult to apply because there are usually many parameters to simulate. For example, you have to simulate the factor loadings, variances, and correlations between factors. If you also want to include potential sources of misfit, you have to additionally simulate different number of factors, cross loadings, and possibly correlated residuals. Compared to a simple mediation model, these are many more parameters to estimate. It doesn’t help that factor analyses are usually used to assess the validity of a new scale, meaning that relatively little is known about the exact parameters, making the simulation extra difficult—possibly too difficult.\nFor instructions on how to conduct Monte Carlo power analyses, see Muthén and Muthén (2002) or Wang and Rhemtulla (2021).\nConclusion: Too difficult for factor analysis purposes.\n\n\nSatorra-Saris method\nThe Satorra-Saris method can be used to estimate the power of model misspecifications.\nThe idea is that there is a population covariance matrix and a model-implied covariance matrix. If the model is correct, the model-implied covariance matrix is the same as the population covariance matrix. If the model is incorrect, there is a misspecification (called \\(F_0\\)). The expected misspecifcation error is a function of the discrepancy and the sample size. This is called the noncentrality parameter, \\(\\lambda\\).\nObtaining the noncentrality parameter is the hard part. It requires specifying both the model you expect to be true and a different model with a different specification that you’d like to be able to detect. This is the hard part because there are many ways for the population model to be different from your model, so you have to decided what kind of misspecification you’d like to be able to detect.\nOnce you have specified both models, you can fit your model to the population model and obtain the \\(χ^2\\) value, which can be used as the noncentrality parameter \\(\\lambda\\).\nYou can also test the difference between two nested models and obtain \\(\\Deltaχ^2\\), which can be used as the noncentrality parameter for comparing these two models.\nCalculating the power once the noncentrality parameter is obtained is easy. You need the degrees of freedom of the model, the alpha, and the power level. You can put these numbers in an online calculators or use R to obtain the sample size needed.\nJust like with the Monte Carlo method, this method seems less suitable for factor analyses because it requires specifying the exact misspecification. Since there are many possible misspecification in a factor analysis, it becomes difficult to figure out what exactly you want to power for. It could be for a cross loading or for a correlated residual between any of the items, or, if there are multiple factors, the correlations between them.\nConclusion: Useful when you have a clear misspecification in mind or when you have two models you want to compare; less useful in factor analysis.\n\n\nRMSEA method\nThe RMSEA method is a power calculation method based on the RMSEA fit index.\nThe RMSEA assumes that the specified model will only be an approximation to reality, and thus some specification error should be allowed\nThe advantage of power calculations using the RMSEA is that the noncentrality parameter (λ) can be derived from the RMSEA. You therefore only need to set the RMSEA of the true model and an alternative model.\nMacCallum et al. (1996) suggested calculating the power to reject close fit (RMSEA ≤ .05) when in the population there is not close fit (RMSEA = .08). Alternatively, you can also flip this logic and calculate the power of no-close fit (RMSEA &gt; .05) while in the population there is a close fit (RMSEA = .01). Jak et al. (2021) recommend power analyses for both the test for close fit and the test for not-close fit.\nAn advantage of this method is that it is easy to use, but a disadvantage is that it is more difficult to interpret because there is no targeted misfit, so you don’t know exactly what kind of misspecifications you’re powering for. This does seem better suited for a factor analysis because it covers multiple kinds of misspecifications.\nAdditionally, this method requires setting good RMSEA cut off points. Although there are some recommendations for which values to use, there is also work showing that the RMSEA cut off points should be determined dynamically, rather than fixed for each model (Wolf & McNeish, 2021). It seems necessary, therefore, to do some prior work to determine what a suitable cut off point could be and use this in subsequent power analyses.\nConclusion: Seems like the best method for determining power for a factor analysis.\n\n\nPower analysis software\nThere are several tools to run power analyses for CFAs.\n\nOnline tools\n\npower4SEM\nWebPower\npwrSEM\n\n\n\nR packages\n\nsemPower\nsemTools",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#number-of-indicators",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#number-of-indicators",
    "title": "Best practices in CFA",
    "section": "Number of indicators",
    "text": "Number of indicators\nSome argue that when it comes to the number of indicators, more is better Marsh et al. (1998).\nOthers say that more is not always better (Koran, 2020). Koran (2020), using a simulation study, showed that:\n\nModels with relatively weak loadings tended to have a larger desirable number of indicators per factor than models with stronger loadings based on considerations of sample size, solution propriety, bias, and power. Models with few factors also tended to have a larger desirable number of indicators per factor than models with more factors. Models with many factors and strong indicators reached a minimum required sample size with as few as three indicators per factor.",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#estimator",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#estimator",
    "title": "Best practices in CFA",
    "section": "Estimator",
    "text": "Estimator\nIf the data is normally distributed, use the ML estimator. If the sample size is sufﬁciently large, the model is speciﬁed correctly, and the data stem from a multivariate normal distribution, the estimator is consistent, efﬁcient, and normally distributed.\nIn case of violations, the following estimators can be used:\n\nMaximum likelihood estimation with robust standard errors and a Satorra-Bentler scaled test statistic (MLM): In case of a normality violation, not as good in the case of a misspecification.\nMaximum likelihood estimation with robust (Huber-White) standard errors and a scaled test statistic that is (asymptotically) equal to the Yuan-Bentler test statistic (MLR): Similar to MLM but better suited for small sample sizes and is robust to both nonnormality and model misfit.\nweighted least squares method (WLS): Requires a large sample size (FLO 04) and frequently runs into convergence issues and improper solutions\nDiagonally Weighted Least Squares (DWLS): For small samples and non-normal data ([JÖR 89)\nWLSM: Robust alternative to DWLS\nWLSMV: Robust alternative to DWLS\nbootstrapping: Not recommended for dichotomous and ordinal measures with few response categories)\n\nMardia calculation to determine violations from normal distribution. It can be noted that not only is this standardized coefficient statistically significant, but its value is greater than 5, which is the threshold value beyond which multivariate normality seems to fail.\n\nRecommendations concerning the main estimators available in lavaan according to the type of data (Gana & Broc).\n\n\n\n\n\n\nData type and normality assumption\nRecommended estimator\n\n\n\n\nContinuous data\n\n\n\nApproximately normal distribution\nML\n\n\nViolation of normality assumption\nML (in case of moderate violation)\n\n\n\nMLM, MLR, Bootstrap\n\n\nOrdinal/categorical data\n\n\n\nApproximately normal distribution\nML (if at least 6 response categories)\n\n\n\nMLM, MLR (if at least 4 response categories)\n\n\n\nWLSMV (binary response or 3 response categories)\n\n\nViolation of normality assumption\nML (if at least 6 response categories)\n\n\n\nMLM, MLR (if at least 4 response categories)\n\n\n\nWLSMV (in case of severe violation)",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#model-evaluation",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#model-evaluation",
    "title": "Best practices in CFA",
    "section": "Model evaluation",
    "text": "Model evaluation\n\nEstimate plausibility\nThe ﬁrst step in evaluating the model ﬁt is to determine the plausibility of the estimates. Values outside their theoretically admissable parameter space (e.g., negative variances) signal that something is wrong.\n\n\nModel fit\nDue to conﬂicting indices and lack of consensus about what constitutes a good ﬁt, a general recommendation is to take a multifaceted approach in which multiple indices are considered jointly (see, e.g., Schermelleh-Engel et al., 2003).\nAlthough the number of available ﬁt indices is relatively large, there is only one that allows for a formal statistical test of overall model ﬁt. By use of the chi-squared, one can test the null hypothesis that the model-implied covariance matrix equals the population covariance matrix\nDespite its intuitive appeal, the test has a couple of drawbacks suggesting that its signiﬁcance level should not be interpreted too strictly. First, it appears to be highly sensitive to sample size. For large samples, the null hypothesis is easily rejected, even for negligable discrepancies (Bentler, 1990). Second, violations of assumptions might inﬂate the values of the test statistic (Kaplan, 2009). Accordingly, Satorra and Bentler (1988, 1994) proposed a scaled version of the test statistic, in which the regular χ 2 is divided by a kurtosis correction factor to better approximate a chi-square under non-normality.\nProbably the most common way to assess model fit is to rely on cut-off points for several fit indices. However, these cut off points make no sense. The reason is that the suitability of a particular model fit index depends on a multitude of factors, including the number of items per factor, factor loading size, type of misspecification, model type, and violations of multivariate normality (Greiff & Heene, 2017). It therefore makes no sense to use one cut-off point for all models.\nInstead, it is recommend to do the following:\nStep 1: Perform the chi squared test and see whether it indicates a significant misfit. Although it appears that the norm is to ignore a significant chi squared test, it seems that is considered to be a mistake, leading to many misfitted models to not be rejected McIntosh (2007).\nStep 2: In the case of a significant chi squared test, inspect potential sources of misfit.\n\nIf your model depends on the multivariate normality assumption, look for signs of a violation of this assumption. Given that much research is done using Likert scales, this could be a likely source. To solve this misfit issue, one can transform the data or use a different estimator.\nInspect the discrepancies between the observed and model-implied covariance matrices.\nUse tools to locate misfits, such as looking at modification indices or performing Fisher’s C test or the Wald test.\n\nNote that it is important to avoid the problem of overfitting. Any modifications to the model should be tested again on new independent data.\nThe modifications should also have a theoretical backing.\nFinally, although it should not be necessary to point this out, but it is possible to be wrong. You may have to conclude that the data simply does not support your theory and that you need to go back to the drawing board.\n\n\nUse flexible cut off points\nSee https://flexiblecutoffs.org\nSee McNeish and Wolf",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#reliability",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#reliability",
    "title": "Best practices in CFA",
    "section": "Reliability",
    "text": "Reliability\nReliability increases the closer the value gets to 1.00, with an acceptability threshold of 0.70.",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#misc",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#misc",
    "title": "Best practices in CFA",
    "section": "Misc",
    "text": "Misc\n\nHow to model reverse-worded items?",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#recommended-reading",
    "href": "content/statistics/factor-analysis/CFA/CFA-best-practices.html#recommended-reading",
    "title": "Best practices in CFA",
    "section": "Recommended Reading",
    "text": "Recommended Reading\n\nDynamic Fit Index Cutoffs for Confirmatory Factor Analysis Models by McNeish & Wolf (2021)",
    "crumbs": [
      "Confirmatory factor analysis",
      "Best practices in CFA"
    ]
  },
  {
    "objectID": "content/statistics/index.html",
    "href": "content/statistics/index.html",
    "title": "Overview",
    "section": "",
    "text": "This section is about statistics-related topics. At the moment there are two chapters. One of exploratory factor analyses and one of confirmatory factor analyses."
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-examples.html",
    "href": "content/statistics/factor-analysis/CFA/CFA-examples.html",
    "title": "CFA - Examples",
    "section": "",
    "text": "# Load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-15\nlavaan is FREE software! Please report any bugs.\n\nlibrary(dynamic)\n\nBeta version. Please report bugs: https://github.com/melissagwolf/dynamic/issues."
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-examples.html#rosenberg-self-esteem-scale",
    "href": "content/statistics/factor-analysis/CFA/CFA-examples.html#rosenberg-self-esteem-scale",
    "title": "CFA - Examples",
    "section": "Rosenberg Self-Esteem Scale",
    "text": "Rosenberg Self-Esteem Scale\nThe Rosenberg self-esteem scale (Rosenberg, 1989) is a unidimensional scale to assess global self-esteem. It is one of the most commonly used scales in psychology and could therefore serve as a nice illustration of how to assess whether the data fits a single factor model.\nIt should be noted, however, that apparently there is some controversy whether the scale is actually unifactorial (Donnellan et al., 2016).\n\nThe Data\n\n# Load data\nitems &lt;- read_csv(\"RSECSV.csv\")\n\nRows: 1127 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (10): R1, R2, R3, R4, R5, R6, R7, R8, R9, R10\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Data preparation\n# Replace all -9999 values with NA\nitems &lt;- mutate(items, across(everything(), ~ na_if(.x, -9999)))\n\nThe data was taken from Donnellan et al. (2016), who conducted a study to assess the factorial structure of the RSE. The data consists of nrow(items) participants, who were college students at a public university in the Southwestern United States.\n\n\nThe Model\n\nmodel &lt;- \"\n  self_esteem =~ R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10\n\"\n\nfit &lt;- cfa(model = model, data = items, estimator = \"MLR\")\nfitmeasures(fit, \n  fit.measures = c(\"pvalue\", \"pvalue.scaled\", \"srmr\", \"rmsea\", \"cfi\"))\n\n       pvalue pvalue.scaled          srmr         rmsea           cfi \n        0.000         0.000         0.082         0.165         0.802 \n\n#fit_cutoffs &lt;- cfaOne(fit)"
  },
  {
    "objectID": "content/statistics/factor-analysis/CFA/CFA-examples.html#marshs-self-description-questionnaire",
    "href": "content/statistics/factor-analysis/CFA/CFA-examples.html#marshs-self-description-questionnaire",
    "title": "CFA - Examples",
    "section": "Marsh’s Self-Description Questionnaire",
    "text": "Marsh’s Self-Description Questionnaire\n\n# Load data\nmarsh &lt;- read_csv(\"marsh.csv\")\n\nRows: 15661 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (13): Eng1, Eng2, Eng3, Eng4, Math1, Math2, Math3, Math4, Par1, Par2, Pa...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nData for this example is from 15,661 students in 10th grade who participated in the National Education Longitudinal Study of 1988. Items from this scale include:\nParents:\n\nMy parents treat me fairly\nI do not like my parents very much\nI get along well with my parents\nMy parents are usually unhappy or disappointed with what I do\nMy parents understand me\n\nEnglish\n\nI learn things quickly in English classes\nEnglish is one of my best subjects\nI get good marks in English\nI’m hopeless in English classes\n\nMathematics\n\nMathematics is one of my best subjects\nI have always done well in mathematics\nI get good marks in mathematics\nI do badly in tests of mathematics\n\n\nmarsh_model &lt;- \"\n  english =~ Eng1 + Eng2 + Eng3 + Eng4\n  math    =~ Math1 + Math2 + Math3 + Math4\n  parent  =~ Par1 + Par2 + Par3 + Par4 + Par5\n\"\n\nmarsh_fit &lt;- cfa(model = marsh_model, data = marsh, estimator = \"MLR\")\nfitmeasures(marsh_fit, \n  fit.measures = c(\"pvalue\", \"pvalue.scaled\", \"srmr\", \"rmsea\", \"cfi\")\n)\n\n       pvalue pvalue.scaled          srmr         rmsea           cfi \n        0.000         0.000         0.051         0.083         0.935 \n\n#marsh_fit_cutoffs &lt;- cfaHB(marsh_fit)"
  },
  {
    "objectID": "content/statistics/factor-analysis/index.html",
    "href": "content/statistics/factor-analysis/index.html",
    "title": "Factor analysis",
    "section": "",
    "text": "This section is about the two types of factor analysis:\n\nExploratory factor analysis (EFA)\nConfirmatory factor analysis (CFA)\n\nEach section consists of a best practices section in which I cover the different decisions you have to make to run the analysis. I cover the literature and offer a conclusion for each step that should be, to my knowledge, the best way to perform that step.\nOther sections consist of an example of the analysis (with code), recommended reading, and a glossary.\nDo note that both sections are still a work in progress.",
    "crumbs": [
      "Factor analysis"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-example.html",
    "href": "content/statistics/factor-analysis/EFA/EFA-example.html",
    "title": "EFA example",
    "section": "",
    "text": "# Load packages\nlibrary(psych)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()   masks psych::%+%()\n✖ ggplot2::alpha() masks psych::alpha()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Exploratory factor analysis",
      "EFA example"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-best-practices.html",
    "href": "content/statistics/factor-analysis/EFA/EFA-best-practices.html",
    "title": "Best practices in EFA",
    "section": "",
    "text": "Warning\n\n\n\nThis chapter is still a work in progress.\nThe goal of an exploratory factor analysis (EFA) is to study latent factors that underlie responses to a larger number of items. In other words, the goal is to explore the data and reduce the number of variables. It is a popular technique in the development and validation of assessment instruments.\nUnlike confirmatory factor analysis (CFA), EFA is used when there is little or no a priori justification for specifying a particular structural model. This means that there is reasonable uncertainty about the number of underlying factors and which items load on which factor. The hope is to resolve some of that uncertainty empirically.",
    "crumbs": [
      "Exploratory factor analysis",
      "Best practices in EFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#preparation",
    "href": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#preparation",
    "title": "Best practices in EFA",
    "section": "Preparation",
    "text": "Preparation\nBefore you perform a factor analysis, make sure that the design of your study is suitable for this type of analysis. This means you should have an appropriate sample, sample size, and indicators (items).\n\nSample\nIt may be obvious, but make sure to target participants that are likely to vary in the attitude that you’re interested in measuring and that the sample is representative of the population that you’re interested in.\n\n\nSample size\nRules of thumb are one way to determine an appropriate sample size, but the general consensus is that rules of thumb are a bad idea Costello & Osborne (2005). The reason for that is that rules of thumb only involve one of two factors: a set number of participants or a particular participant-to-item ratio. The reality is that the appropriate sample size is dependent on many more factors, such as communalities, factor loadings, the number of indicators per factor, the number of factors, and more Velicer & Fava (1998).\nGiven the replication failures in the social sciences, it should be no surprise that also in the EFA literature there appears to be a sample size problem. This is perhaps best demonstrated by Costello & Osborne (2005). They reviewed two years’ worth of PsychINFO articles and found that the majority of the studies (62.9%) had participants to item ratios of 10:1 or less. Of course, the participant to item ratio is not a good benchmark for the appropriate sample size, so this is not enough to demonstrate that the sample size is insufficient. They did find support that this is not enough by sampling data of various sample sizes from a large data set of responses to the Marsh’s Self-Description Questionnaire. They found that only 70% of their large (20:1) samples produced correct solutions, leading them to conclude that a 20:1 participant to item ratio produces error rates well above the field standard alpha = .05 level.\nSo how many participants should you recruit? In my opinion, the most useful study is a simulation study by Mundfrom et al. (2005). They ran simulations to determine the minimum sample size for a study, taking into account the number of factors, the ratio of items to factors, and several different communalities. They generated a variety of population correlation matrices under different conditions, repeatedly sampled from these population structures, and determined coefficients of congruence between the sample solutions and population structures (similar to Velicer & Fava (1998)). This allowed them to produce a table with minimum recommend sample sizes for different situations.\n\nRecommended minimum sample sizes by Mundfrom et al. (2005)\n\n\n\n\n\n\n\n\nCriterion\nCommunality\nItems per factor\nMinimum sample size\n\n\n\n\nExcellent (0.98)\nHigh (.6 to .8)\n4\n500\n\n\n\n\n6\n250\n\n\n\n\n8\n100\n\n\n\nWide (.2 to .8)\n4\n900\n\n\n\n\n6\n200\n\n\n\n\n8\n130\n\n\n\nLow (.2 to .4)\n4\n1400\n\n\n\n\n6\n260\n\n\n\n\n8\n130\n\n\nGood (0.92)\nHigh (.6 to .8)\n5\n130\n\n\n\n\n7\n55\n\n\n\nWide (.2 to .8)\n5\n140\n\n\n\n\n8\n60\n\n\n\nLow (.2 to .4)\n5\n200\n\n\n\n\n8\n80\n\n\n\nAs can be seen in the table, the appropriate sample size is dependent on several factors and is not simply a function of sample size alone or a particular participant to item ratio.\n\n\nNumber of items\nThe previous section on sample size shows that a relevant factor in determining the minimum sample size is the number of items per factor, so how many items should you create and include in the factor analysis?\nSince this is an exploratory factor analysis, it is not clear in advance how many items will actually survive the exploration. It could be that certain items will not be well understood by participants (although this should be caught in pilot testing prior to running an EFA) or that multiple items simple do not fit in the expected factor structure. Since not all items will likely behave well, you should always include more items than you intend to keep.\nIt’s also useful to keep in mind that for a single factor model to be identifiable, it must consist of at least three indicators and preferably four to also allow for the model to be statistically testable Russell (2002). This is useful for when you want to do a CFA later or if you want others to be able to perform CFAs on your factor analysis results.\nThe number of indicators also depends on the quality of indicators. Costello & Osborne (2005) notes that 5 or more strongly loading items (.50 or better) indicate a solid factor. MacCallum et al. (1999) writes that more indicators is generally better Hayduk & Littvay (2012). Within the range of indicators they studied (three to seven per factor), it is better to have more indicators than fewer. The critical point, however, is that these indicators must be reasonably valid and reliable.\nVelicer & Fava (1998) suggest that 6-10 initial items per factor is recommended as 25% to 50% will not perform as expected and the end goal should be to have four- or five to-one as a minimum. The bare minimum of three variables was found to be insufficient (based on two simulation studies) and a more prudent target would be to have four- or five to-one as a minimum. A ratio of 20-30 initial items per factor is also possible as an appropriate target for extensive oversampling, which may be needed in cases where it is not possible to obtain a large sample size.\nFinally, you should also take into account the desirable scale length. Shorter scales have the desirable property that they are quick to administer, meaning they can more easily be added to a study or included in short studies to obtain a larger sample size. The goal may therefore be to find only a handful of solid indicators for a factor.",
    "crumbs": [
      "Exploratory factor analysis",
      "Best practices in EFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#data-analysis",
    "href": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#data-analysis",
    "title": "Best practices in EFA",
    "section": "Data Analysis",
    "text": "Data Analysis\n\nRelevant items\nOne design issue that is especially important is about which measured variables to include in the study. If measured variables irrelevant to the domain of interest are included, then spurious common factors might emerge or true common factors might be obscured (Fabrigar et al., 1999).\n\n\nSampling Adequacy\nThe Kaiser–Meyer–Olkin (KMO) test is a statistical measure to determine how suitable the data is for factor analysis. The test measures sampling adequacy for the complete model and each variable in the model. The statistic indicates the degree to which each variable in a set is predicted without error by the other variables.\nThe KMO value ranges from 0 to 1, with 0.60 considered suitable for factor analysis (Tabachnick & Fidell, 2013). Kaiser (1974) himself suggested that KMO &gt; .9 were marvelous, in the .80s, meritorious, in the .70s, middling, in the .60s, mediocre, in the 50s, miserable, and less than .5, unacceptable.\nBartlett’s test of sphericity is a notoriously sensitive test of the hypothesis that the correlations in a correlation matrix are zero. Because of its sensitivity and its dependence on N, the test is likely to be significant with samples of substantial size even if correlations are very low. Therefore, use of the test is recommended only if there are fewer than around five participants per variable (Tabachnick & Fidell, 2013).\n\n\nPrincipal Components vs. Factor Analysis\nAn important consideration is whether to use a principal components analysis (PCA) or a factor analysis. PCA is a data reduction technique and while a factor analysis is also a type of data reduction technique, the focus with PCA is more on simply reducing the data, without regard for a theoretical interpretation. With PCA, the variables themselves are of interest, rather than a hypothetical latent construct. Constructs are conceptualized as being causally determined by the observations; that is, CFA reflects a formative model rather than a reflective one (Edwards & Bagozzi, 2000). If you are a psychologist trying to create a measure of a psychological construct, this is probably not what you want as principal component scores are “caused” by their indicators in much the same way that sum scores are “caused” by item scores.” (Borsboom, 2006, p. 426). Instead, you likely want the opposite causal relationship in which a latent factor causes the indicator scores.\n\n\nCode\nDiagrammeR::grViz(\"\n  digraph dot {\n    graph [\n      layout = dot, \n      rankdir = LR, \n      fontname = 'Source Sans Pro', \n      label = 'Illustration of a PCA model (left) and a factor analysis model (right).'\n    ]\n    \n    node [fontname = 'Source Sans Pro']\n    node [shape = square]\n    var1 [label = 'item 1']\n    var2 [label = 'item 2']\n    var3 [label = 'item 3']\n    var4 [label = 'item 4']\n    var5 [label = 'item 1']\n    var6 [label = 'item 2']  \n    var7 [label = 'item 3']  \n    var8 [label = 'item 4']\n  \n    node [shape = circle]\n    construct_a [label = 'construct A']\n    construct_b [label = 'construct B']\n  \n    edge [color = black, minlen = 3]\n    {var1 var2 var3 var4} -&gt; construct_a\n    construct_b -&gt; {var5 var6 var7 var8}\n  \n    edge[style = invis, minlen = 1];\n    construct_a -&gt; construct_b\n  }\"\n)\n\n\n\n\n\n\nA related issue is that factor analysis assumes that the total variance can be partitioned into common and unique variance and PCA assumes that the common variances takes up all of total variance. This means that PCA assumes that all variables are measured without error. It is usually more reasonable to assume that you have not measured your set of items perfectly.\nAlthough some argue that the two methods have the same results (Velicer & Jackson, 1990), there is evidence that those similarities are mistaken and that factor analysis has better results than PCA (Widaman, 1993).\nConclusion: Do not use PCA.\n\n\nNumber of factors\nThere are many different methods to determine how many factors to retain. Some popular methods are:\n\nTheory\nKaiser criterion\nScree test\nParallel analysis\nVelicer’s multiple average partial (MAP) procedure\nAkaike information criterion\nBayesian information criterion\nComparison data\nVery Simple Structure (VSS)\nThe root-mean-square error of approximation\nLikelihood ratio statistic\n\nDetermining the number of factors is probably the most difficult part of the exploratory factor analysis. As Henry Kaiser said:\n\nSolving the number of factors problem is easy, I do it everyday before breakfast. But knowing the right solution is harder.\n\nThe difficulty of this step means that a certain flexibility is warranted.\nIt makes sense to begin with the expectation that you will see the theorized factor structure. Instruments are rarely perfect (especially the first time it is examined), and theoretical expectations are not always supported, but unless one is on a totally blind fishing expedition, this is a good place to start.\nThe default in most statistical software packages is to use the Kaiser criterion. It makes some sense, as an eigenvalue represents the sum of the squared factor loadings in a column, and to get a sum of 1.0 or more, one must have rather large factor loadings to square and sum. However, this is easily achieved with more items and there are now alternative methods. Hence, there is broad consensus in the literature that this is among the least accurate methods for selecting the number of factors to retain (Velicer & Jackson, 1990).\nThe scree test involves examining the graph of the eigenvalues and looking for the natural bend or “elbow” in the data where the slope of the curve changes markedly. Although the scree plot itself is not considered sufficient to determine how many factors should be extracted (Velicer et al., 2000), it does appear to be a relatively reliable method. The main down side seems to be its ambiguity as the bend is not always clear and sometimes there are even multiple bends.\nParallel analysis involves generating random uncorrelated data, and comparing eigenvalues from the EFA to the eigenvalues from the random data. Using this process, only factors with eigenvalues that are above random eigenvalues should be retained, although it is not clear how much above the random eigenvalues they should be. Several authors have endorsed this as the most robust and accurate process for determining the number of factors to extract Velicer et al. (2000).\nThe Minimum Average Partial (MAP) criterion involves partialing out common variance as each successive component is created. As each successive component is partialed out, common variance will decrease to a minimum. Velicer argued that minimum point should be considered the criterion for the number of factors to extract.\nVSS involves degrading the initial rotated factor solution by assuming that the nonsalient loadings are zero, even though in actuality they rarely are. What VSS does is test how well the factor matrix we think about and talk about actually fits the correlation matrix. It is not a confirmatory procedure for testing the significance of a particular loading, but rather it is an exploratory procedure for testing the relative utility of interpreting the correlation matrix in terms of a family of increasingly more complex factor models. The simplest model tested by VSS is that each item is of complexity one, and that all items are embedded in a more complex factor matrix of rank k. This is the model most appropriate for scale construction and is the one we use most frequently when we talk about factor solutions. More complicated models may also be evaluated by VSS.\nZwick & Velicer (1986) tested the scree test, Horn’s parallel test, and Velicer’s MAP test (among others) in simulation studies using a data set with a clear factor structure. Both the parallel test and MAP test seemed to work well. Ruscio & Brendan Roche (2012) notes that PA is considered to be the method of choice among methodologists and recommend that researchers take advantage of PA as a starting point, perhaps supplemented by CD. They note that researchers can also use more than one method. Osborne (2014) notes that MAP has been considered superior to the “classic” criteria, and probably is superior to parallel analysis, although neither is perfect, and all must be used in the context of a search for conceptually interpretable factors. He recommends to use parallel analysis or MAP criteria, along with theory (and any of the classic criteria that suits you and is defensible). Another simulation study, perhaps the most comprehensive one so far, also shows that the results of multiple methods should be taken into consideration (Auerswald & Moshagen, 2019). They recommend that investigators compare the results of sequential \\(\\chi^2\\) model tests and either PAPCA-95, Hull, or the Empirical Kaiser Criterion (EKC). If both methods suggest the same number of factors, this most often reflects the correct number of underlying factors. If the methods disagree, CD, the EKC, or one of the variants of traditional PAPCA are viable extraction criteria provided that the sample is large. They also note the importance of theoretical considerations and that the resulting factor loading patterns should be interpretable and that the scale reliabilities should also be taken into account.\nFinally, empirical research suggests that overfactoring introduces much less error to factor loading estimates than under factoring Wood et al. (1996). Although you should be skeptical of solutions with too many factors because the factors may not be meaningful and parsimony should also be considered.\nConclusion: Use multiple criteria, including theory, to make a judgment call about how many factors to extract. When in doubt, favor more factors rather than fewer factors.\n\n\nFactor Extraction Method\nExtraction is the general term for the process of reducing the number of dimensions being analyzed from the number of variables in the data set (and matrix of associations) into a smaller number of factors.\nThere are multiple factor extraction methods, such as:\n\nminres\nunweighted least squares (ULS)\ngeneralized least squares (GLS)\nmaximum likelihood\nprincipal axis factor(ing)\nalpha factor(ing)\nimage factor(ing)\n\nIt’s not entirely clear which factor extraction method is the best and some authors use different terms for some of the methods, making it more difficult to compare them.\nFabrigar et al. (1999) argued that if data are relatively normally distributed, maximum likelihood is the best choice because “it allows for the computation of a wide range of indexes of the goodness of fit of the model and permits statistical significance testing of factor loadings and correlations among factors and the computation of confidence intervals.” (p. 277). In case the data is not generally normally distributed, they recommend principal axis factoring. This is recommended in several sources (Costello & Osborne (2005); Osborne (2014)).\nConclusion: Use the maximum likelihood method if the data is generally normally distributed and to use principal axis factoring if the data is non-normal.\n\n\nRotation methods\nThe goal of rotation is to clarify the factor structure and make the results of the EFA more interpretable.\nRotation methods can be categorized into one of two categories: orthogonal or oblique. Orthogonal rotations keep axes at a 90 degree angle, forcing the factors to be uncorrelated. Oblique rotations allow angles that are not 90 degrees , thus allowing factors to be correlated if that is optimal for the solution.\nOrthogonal rotation methods include:\n\nvarimax\nquartimax\nequamax\n\nOblique rotation methods include:\n\ndirect oblimin\nquartimin\npromax\n\nIn the social sciences, we generally expect some correlation among factors, since behavior is rarely partitioned into neatly packaged units that function independently of one another. Therefore using orthogonal rotation results in a loss of valuable information if the factors are correlated, and oblique rotation should theoretically render a more accurate, and perhaps more reproducible, solution. If the factors are truly uncorrelated, orthogonal and oblique rotation produce nearly identical results. Since oblique rotation will reproduce an orthogonal solution but not vice versa, it makes sense to go for oblique rotation.\nThere is no widely preferred method of oblique rotation; all tend to produce similar results (Fabrigar et al., 1999).\nConclusion: Use any oblique rotation.",
    "crumbs": [
      "Exploratory factor analysis",
      "Best practices in EFA"
    ]
  },
  {
    "objectID": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#interpretation",
    "href": "content/statistics/factor-analysis/EFA/EFA-best-practices.html#interpretation",
    "title": "Best practices in EFA",
    "section": "Interpretation",
    "text": "Interpretation\nRemember that the goal of exploratory factor analysis is to explore whether your data fits a model that makes sense. Ideally, you have a conceptual or theoretical framework for the analysis. Even if you do not, the results should be sensible in some way. You should be able to construct a simple narrative describing how each factor, and its items, makes sense and is easily labeled.\n\nFactor Loadings\nAfter determining the number of factors and rotation, you will be able to produce a table of factor loadings. The question is now to see whether there are items that load sufficiently strongly on each factor. If the goal is to have unidimensional factors, then cross loadings should also be examined. Items that don’t perform well may be removed.\nThere are different recommendations about what kind of factor loading cutoff threshold to use. Comrey & Lee (1992) suggest that loadings in excess of .71 (50% overlapping variance) are considered excellent, .63 (40% overlapping variance) very good, .55 (30% overlapping variance) good, .45 (20% overlapping variance) fair, and .32 (10% overlapping variance) poor. Tabachnick & Fidell (2013) cite .32 as a good rule of thumb for the minimum loading of an item, assuming the sample size is larger than 300. Others say item loadings above .30 (Costello & Osborne, 2005). Clark & Watson (1995) say larger than .35.\nIn a review on the topic, Peterson (2000) found that the average factor loading cutoff threshold is .40.\nUsing a particular threshold is, however, insufficient if sample size is not taken into account. Factor loadings, like many other statistics, are estimated statistics and may be associated with large uncertainty intervals, depending on the sample size. It’s possible for a sample factor loading of .70 to be 0 in the population, if the sample size was low (Cudeck & O’Dell, 1994). A first benchmark, therefore, should be whether the factor loading is significantly different from 0. The standard errors of factor loadings can be calculated in different ways. If computational power is not an issue, non-parametric bootstrapping seems to be the preferred method (Zhang, 2014).\nNote that a multiple comparisons correction (e.g., Bonferonni) must be used to control familywise Type 1 errors.\nFinally, one must be careful not to prematurely drop poorly performing items, especially when such items were predicted a priori to be strong markers of a given factor.\nConclusion: Calculate standard errors for factor loadings and use significance tests as the first benchmark to retain an item.\n\n\nReliability\nThere are different types of reliabilities that can be calculated to assess the reliability of the scale:\n\nInternal consistency\nTest-retest reliability\n\nCronbach’s alpha is the most popular measure of internal reliability, with recommended cutoffs of .80 in a basic science setting and .9 or .95 in an applied setting (Clark & Watson, 1995). Note that Cronbach’s alpha relies on the assumption of unidimensionality, which means it cannot be used as evidence for unidimensionality. In fact, Cronbach’s alpha’s assumes equally sized factor loadings. Given that this is an unlikely assumption, and that Cronbach’s alpha is also influenced by the number of items, alternative measures of reliability should be used Hayes & Coutts (2020).\nMcDonald’s omega does not assume equally sized factor loadings. Cronbach’s alpha is actually a special case of McDonald’s omega, assuming the untenable assumption of equally sized factor loadings.\nConclusion: Use McDonald’s omega.",
    "crumbs": [
      "Exploratory factor analysis",
      "Best practices in EFA"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/sequential-analyses.html",
    "href": "content/statistics/group-differences/sequential-analyses.html",
    "title": "Sequential analyses",
    "section": "",
    "text": "Code\n# Load packages\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(brms)\nlibrary(emmeans)\nlibrary(BayesFactor)\nlibrary(tidybayes)\n\n# Set the default ggplot theme\ntheme_set(theme_minimal())\n\n# Set seed\nset.seed(1)\nThis section is about performing sequential analyses.",
    "crumbs": [
      "Sequential analyses"
    ]
  },
  {
    "objectID": "content/statistics/group-differences/sequential-analyses.html#bayesian",
    "href": "content/statistics/group-differences/sequential-analyses.html#bayesian",
    "title": "Sequential analyses",
    "section": "Bayesian",
    "text": "Bayesian\n\nTwo groups\nFor this scenario we simulate data from two different groups (say a control group and an experimental group).\n\n\nCode\n# Set the simulation parameters\nMs &lt;- c(0, 0.25)\nSDs &lt;- 1\nn &lt;- 250\nlabels &lt;- c(\"control\", \"experimental\")\n\n# Produce the variance-covariance matrix\nSigma &lt;- matrix(\n  nrow = length(Ms),\n  ncol = length(Ms),\n  data = c(\n    SDs^2, 0,\n    0, SDs^2\n  )\n)\n\n# Simulate\nm &lt;- mvrnorm(n = n, mu = Ms, Sigma = Sigma, empirical = TRUE)\n\n# Prepare data\ncolnames(m) &lt;- labels\n\ndata &lt;- as_tibble(m)\n\ndata &lt;- pivot_longer(\n  data = data,\n  cols = everything(),\n  names_to = \"condition\",\n  values_to = \"DV\"\n)\n\ndata &lt;- mutate(data, id = 1:n(), .before = condition)\n\n\nThere are different Bayesian ways to analyze this data. One can focus on estimation or on Bayes factors.\n\nEstimation\nIf estimation is the goal, we run the model (or models) and obtain the posterior distribution of the estimates of interest. Below we run subsequent models with each model using more of the data.\n\n\nCode\nns &lt;- c(10, 20, 30, 40, 50, 75, 100, 150, 200, 250)\nresults &lt;- tibble()\n\nfor (i in 1:length(ns)) {\n  # Get the sample size\n  n &lt;- ns[i]\n\n  # Draw a sample of size n\n  sample &lt;- slice_head(data, n = n)\n\n  # If this is the first iteration, run the full brms model\n  # Else update the model\n  if (i == 1) {\n    model &lt;- brm(\n      formula = DV ~ 0 + Intercept + condition,\n      data = sample,\n      family = gaussian(),\n      prior = c(\n        set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n      )\n    )\n  } else {\n    model &lt;- update(model, newdata = sample)\n  }\n\n  # Get the posteriors of the model estimates\n  draws &lt;- as_draws_df(model)\n\n  # Add sample information\n  draws &lt;- mutate(draws, step = i, n = n)\n\n  # Add the draws to the results data frame\n  results &lt;- bind_rows(\n    results,\n    draws\n  )\n}\n\n\nNow we have the draws of the posterior distribution of the model estimates. We can plot these using the following code.\n\n\nCode\nfinal_quantiles &lt;- results %&gt;%\n  filter(n == 250) %&gt;%\n  pull(b_conditionexperimental) %&gt;%\n  quantile(probs = c(.025, .975))\n\nggplot(results, aes(x = factor(n), y = b_conditionexperimental)) +\n  stat_halfeye() +\n  geom_hline(yintercept = final_quantiles, linetype = \"dashed\", alpha = .5) +\n  labs(x = \"Sample size per condition (n)\", y = \"\")\n\n\n\n\n\nHorizontal lines show the 95% interval of the estimate from the largest sample.\n\n\n\nSequential analyses of 2 groups\n\n\n\nBayes factors\nThis is still a work in progress. I have yet to figure out the best way to obtain Bayes factors using the brms package.\nBelow I use both brms and BayesFactor to calculate Bayes factors for the effect of condition across various sample sizes.\n\n\nCode\n#|\n#| cache: true\nns &lt;- c(10, 20, 30, 40, 50, 75, 100, 150, 200, 250)\nresults &lt;- tibble()\n\nfor (i in 1:length(ns)) {\n  # Get the sample size\n  n &lt;- ns[i]\n\n  # Draw a sample of size n\n  sample &lt;- slice_head(data, n = n)\n\n  # If this is the first iteration, run the full brms model\n  # Else update the model\n  if (i == 1) {\n    model &lt;- brm(\n      formula = DV ~ 0 + Intercept + condition,\n      data = sample,\n      family = gaussian(),\n      prior = c(\n        set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n      ),\n      sample_prior = TRUE\n    )\n  } else {\n    model &lt;- update(model, newdata = sample)\n  }\n\n  # Calculate the BF\n  BF_brms &lt;- hypothesis(model, \"conditionexperimental = 0\")\n\n  # Also calculate the BF with the testBF() function from BayesFactor\n  BF_BF &lt;- ttestBF(formula = DV ~ condition, data = as.data.frame(sample))\n\n  # Add the information to the bayes factors data frame\n  results &lt;- bind_rows(\n    results,\n    tibble(\n      step = i,\n      n = n,\n      brms = BF_brms$hypothesis$Evid.Ratio,\n      BayesFactor = extractBF(BF_BF)$bf\n    )\n  )\n}\n\n\nNext we plot the Bayes factors for each sample size and for each method of calculating the Bayes factor.\n\n\nCode\nresults_long &lt;- results %&gt;%\n  mutate(BayesFactor = 1 / BayesFactor) %&gt;%\n  pivot_longer(\n    cols = c(brms, BayesFactor),\n    names_to = \"method\",\n    values_to = \"BF\"\n  )\n\nggplot(\n  data = results_long,\n  mapping = aes(x = factor(n), y = BF, linetype = method, group = method)\n) +\n  geom_line() +\n  labs(\n    x = \"Sample size per condition (n)\",\n    y = expression(BF[\"10\"]),\n    linetype = \"Method\"\n  )\n\n\n\n\n\nBayes factors per sample size\n\n\n\n\n\n\n\nFour groups\nLet’s simulate data for a scenario in which we have 4 different between-subjects conditions. The conditions differ from each by a small amount and for simplicity’s sake each condition has a standard deviation of 1.\n\n\nCode\n# Set the simulation parameters\nMs &lt;- c(0, 0.2, 0.4, 0.6)\nSDs &lt;- 1\nn &lt;- 250\nlabels &lt;- c(\"A\", \"B\", \"C\", \"D\")\n\n# Produce the variance-covariance matrix\nSigma &lt;- matrix(\n  nrow = length(Ms),\n  ncol = length(Ms),\n  data = c(\n    SDs^2, 0, 0, 0,\n    0, SDs^2, 0, 0,\n    0, 0, SDs^2, 0,\n    0, 0, 0, SDs^2\n  )\n)\n\n# Simulate\nm &lt;- mvrnorm(n = n, mu = Ms, Sigma = Sigma, empirical = TRUE)\n\n# Prepare data\ncolnames(m) &lt;- labels\n\ndata &lt;- as_tibble(m)\n\ndata &lt;- pivot_longer(\n  data = data,\n  cols = everything(),\n  names_to = \"condition\",\n  values_to = \"DV\"\n)\n\ndata &lt;- mutate(data, id = 1:n(), .before = condition)\n\n\n\nEstimation\nWith this data we can run multiple sequential models (like in the 2 groups scenario), except this time we calculate contrasts between all the levels of the condition factor. We again obtain the posteriors of these contrasts and store them so we can plot them afterwards.\n\n\nCode\nns &lt;- c(10, 20, 30, 40, 50, 75, 100, 150, 200, 250)\nresults &lt;- tibble()\n\nfor (i in 1:length(ns)) {\n  # Get the sample size\n  n &lt;- ns[i]\n\n  # Draw a sample of size n\n  sample &lt;- slice_head(data, n = n)\n\n  # If this is the first iteration, run the full brms model\n  # Else update the model\n  if (i == 1) {\n    model &lt;- brm(\n      formula = DV ~ 0 + Intercept + condition,\n      data = sample,\n      family = gaussian(),\n      prior = c(\n        set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n      )\n    )\n  } else {\n    model &lt;- update(model, newdata = sample)\n  }\n\n  # Get the estimated marginal means\n  emmeans &lt;- emmeans(model, specs = pairwise ~ condition)\n  contrasts &lt;- emmeans$contrasts\n\n  # Get draws of the posterior of each contrast\n  draws &lt;- gather_emmeans_draws(contrasts)\n\n  # Add sample information\n  draws &lt;- mutate(draws, step = i, n = n)\n\n  # Add the draws to the results data frame\n  results &lt;- bind_rows(\n    results,\n    draws\n  )\n}\n\n\nNow that we have a data frame that contains the posterior draws of each contrast, we can plot the posteriors as well as some summary statistics (e.g., the median, a 95% interval) for each contrast.\n\n\nCode\nfinal_quantiles &lt;- results %&gt;%\n  filter(n == 250) %&gt;%\n  group_by(contrast) %&gt;%\n  summarize(\n    final_lower = quantile(.value, .025),\n    final_upper = quantile(.value, .975)\n  ) %&gt;%\n  pivot_longer(cols = -contrast, names_to = \"bound\", values_to = \"value\")\n\nggplot(results, aes(x = factor(n), y = .value)) +\n  stat_slabinterval() +\n  geom_hline(\n    mapping = aes(yintercept = value),\n    data = final_quantiles,\n    linetype = \"dashed\",\n    alpha = .5\n  ) +\n  facet_wrap(~contrast, ncol = 1, scales = \"free_y\") +\n  labs(x = \"Sample size per condition (n)\", y = \"Contrast estimate\") +\n  scale_color_viridis(option = \"mako\", discrete = TRUE)\n\n\n\n\n\nHorizontal lines show the 95% interval of the estimate from the largest sample.\n\n\n\nSequential analysis\n\n\n\nBayes factors\nBelow we run the same models but this time we calculate Bayes factors for each contrast using the hypothesis() function.\n\n\nCode\nns &lt;- c(10, 20, 30, 40, 50, 75, 100, 150, 200, 250)\nresults &lt;- tibble()\n\nfor (i in 1:length(ns)) {\n  # Get the sample size\n  n &lt;- ns[i]\n\n  # Draw a sample of size n\n  sample &lt;- slice_head(data, n = n)\n\n  # If this is the first iteration, run the full brms model\n  # Else update the model\n  if (i == 1) {\n    model &lt;- brm(\n      formula = DV ~ 0 + Intercept + condition,\n      data = sample,\n      family = gaussian(),\n      prior = c(\n        set_prior(coef = \"Intercept\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"b\", prior = \"normal(0, 1)\"),\n        set_prior(class = \"sigma\", prior = \"normal(1, 1)\")\n      ),\n      sample_prior = TRUE\n    )\n  } else {\n    model &lt;- update(model, newdata = sample)\n  }\n\n  # Get the bayes factors for each contrast\n  BF_AB &lt;- hypothesis(model, \"Intercept = conditionB\")\n  BF_AC &lt;- hypothesis(model, \"Intercept = conditionC\")\n  BF_AD &lt;- hypothesis(model, \"Intercept = conditionD\")\n  BF_BC &lt;- hypothesis(model, \"conditionB = conditionC\")\n  BF_BD &lt;- hypothesis(model, \"conditionB = conditionD\")\n  BF_CD &lt;- hypothesis(model, \"conditionC = conditionD\")\n\n  # Create a tibble with the Bayes factors and sample information\n  bayes_factors &lt;- tibble(\n    i = i,\n    n = n,\n    `A - B` = BF_AB$hypothesis$Evid.Ratio,\n    `A - C` = BF_AC$hypothesis$Evid.Ratio,\n    `A - D` = BF_AD$hypothesis$Evid.Ratio,\n    `B - C` = BF_BC$hypothesis$Evid.Ratio,\n    `B - D` = BF_BD$hypothesis$Evid.Ratio,\n    `C - D` = BF_CD$hypothesis$Evid.Ratio\n  )\n\n  # Add the draws to the results data frame\n  results &lt;- bind_rows(\n    results,\n    bayes_factors\n  )\n}\n\n\nNext, we plot the Bayes factors over time, for each contrast.\n\n\nCode\nresults_long &lt;- results %&gt;%\n  pivot_longer(cols = -c(i, n), names_to = \"contrast\", values_to = \"BF\") %&gt;%\n  mutate(BF = if_else(BF &lt; 1, log(BF), BF))\n\nggplot(data = results_long, mapping = aes(x = factor(n), y = BF, group = 1)) +\n  geom_line() +\n  facet_wrap(~contrast) +\n  labs(\n    x = \"Sample size per condition (n)\",\n    y = expression(BF[\"10\"]),\n    linetype = \"Method\"\n  )",
    "crumbs": [
      "Sequential analyses"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html",
    "href": "content/materials/scales/OUS/OUS.html",
    "title": "Oxford Utilitarianism Scale",
    "section": "",
    "text": "The scale consists of 9 items in two subscales. The first subscale–Impartial Beneficence (OUSIB)–consists of 5 items that all tap endorsement of the impartial maximization of the greater good, even at the cost of personal self-sacrifice. The second subscale was labeled Instrumental Harm (OUS-IH). This subscale consists of 4 items that all tap into a willingness to cause harm to bring about the greater good.",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html#items",
    "href": "content/materials/scales/OUS/OUS.html#items",
    "title": "Oxford Utilitarianism Scale",
    "section": "Items",
    "text": "Items\n\nIf the only way to save another person’s life during an emergency is to sacrifice one’s own leg, then one is morally required to make this sacrifice.\nIt is morally right to harm an innocent person if harming them is a necessary means to helping several other innocent people.\nFrom a moral point of view, we should feel obliged to give one of our kidneys to a person with kidney failure since we don’t need two kidneys to survive, but really only one to be healthy.\nIf the only way to ensure the overall well-being and happiness of the people is through the use of political oppression for a short, limited period, then political oppression should be used.\nFrom a moral perspective, people should care about the well-being of all human beings on the planet equally; they should not favor the well-being of people who are especially close to them either physically or emotionally.\nIt is permissible to torture an innocent person if this would be necessary to provide information to prevent a bomb going off that would kill hundreds of people.\nIt is just as wrong to fail to help someone as it is to actively harm them yourself.\nSometimes it is morally necessary for innocent people to die as collateral damage if more people are saved overall.\nIt is morally wrong to keep money that one doesn’t really need if one can donate it to causes that provide effective help to those who will benefit a great deal.",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html#instructions",
    "href": "content/materials/scales/OUS/OUS.html#instructions",
    "title": "Oxford Utilitarianism Scale",
    "section": "Instructions",
    "text": "Instructions\n\nIndicate how much you agree or disagree with each of the following statements (1 = strongly disagree, 4 = neither agree nor disagree, 7 = strongly agree)",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html#response-options",
    "href": "content/materials/scales/OUS/OUS.html#response-options",
    "title": "Oxford Utilitarianism Scale",
    "section": "Response options",
    "text": "Response options\nA 7-point Likert scale with at least 3 of the response options labeled: 1 = strongly disagree, 4 = neither agree nor disagree, 7 = strongly agree.",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html#download",
    "href": "content/materials/scales/OUS/OUS.html#download",
    "title": "Oxford Utilitarianism Scale",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/OUS/OUS.html#reference",
    "href": "content/materials/scales/OUS/OUS.html#reference",
    "title": "Oxford Utilitarianism Scale",
    "section": "Reference",
    "text": "Reference\n\n\nKahane, G., Everett, J. A. C., Earp, B. D., Caviola, L., Faber, N. S., Crockett, M. J., & Savulescu, J. (2018). Beyond sacrificial harm: A two-dimensional model of utilitarian psychology. Psychological Review, 125(2), 131–164. https://doi.org/10.1037/rev0000093",
    "crumbs": [
      "Ethics",
      "Oxford Utilitarianism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/index.html",
    "href": "content/materials/scales/index.html",
    "title": "Scales",
    "section": "",
    "text": "Here you can find a list of scales to use in your research!",
    "crumbs": [
      "Scales"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html",
    "href": "content/materials/scales/DOSPERT/dospert.html",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "",
    "text": "Domain-Specific Risk-Taking (DOSPERT) Scale is a psychometric scale that assesses general and domain-specific dimensions of risk preference: financial decisions (separately for investing versus gambling), health/safety, recreational, ethical, and social decisions. Respondents rate the likelihood that they would engage in domain-specific risky activities.",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html#items",
    "href": "content/materials/scales/DOSPERT/dospert.html#items",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "Items",
    "text": "Items\n\nAdmitting that your tastes are different from those of a friend.\nGoing camping in the wilderness.\nBetting a day’s income at the horse races.\nInvesting 10% of your annual income in a moderate growth mutual fund.\nDrinking heavily at a social function.\nTaking some questionable deductions on your income tax return.\nDisagreeing with an authority ﬁgure on a major issue.\nBetting a day’s income at a high-stake poker game.\nHaving an affair with a married man/woman.\nPassing off somebody else’s work as your own.\nGoing down a ski run that is beyond your ability.\nInvesting 5% of your annual income in a very speculative stock.\nGoing whitewater rafting at high water in the spring.\nBetting a day’s income on the outcome of a sporting event\nEngaging in unprotected sex.\nRevealing a friend’s secret to someone else.\nDriving a car without wearing a seat belt.\nInvesting 10% of your annual income in a new business venture.\nTaking a skydiving class.\nRiding a motorcycle without a helmet.\nChoosing a career that you truly enjoy over a more secure one. 11\nSpeaking your mind about an unpopular issue in a meeting at work.\nSunbathing without sunscreen.\nBungee jumping off a tall bridge.\nPiloting a small plane.\nWalking home alone at night in an unsafe area of town.\nMoving to a city far away from your extended family.\nStarting a new career in your mid-thirties.\nLeaving your young children alone at home while running an errand.\nNot returning a wallet you found that contains $200.",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html#instructions",
    "href": "content/materials/scales/DOSPERT/dospert.html#instructions",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "Instructions",
    "text": "Instructions\nDomain-Speciﬁc Risk-Taking (Adult) Scale — RT scale:\n\nFor each of the following statements, please indicate the likelihood that you would engage in the described activity or behavior if you were to ﬁnd yourself in that situation. Provide a rating from Extremely Unlikely to Extremely Likely, using the following scale: Extremely Unlikely, Moderately Unlikely, Somewhat Unlikely, Not Sure, Somewhat Likely, Moderately Likely, Extremely Likely\n\nDomain-Speciﬁc Risk-Taking (Adult) Scale — RP subscale\n\nPeople often see some risk in situations that contain uncertainty about what the outcome or consequences will be and for which there is the possibility of negative consequences. However, riskiness is a very personal and intuitive notion, and we are interested in your gut level assessment of how risky each situation or behavior is.\nFor each of the following statements, please indicate how risky you perceive each situation. Provide a rating from Not at all Risky to Extremely Risky, using the following scale: Not at all Risky, Slightly Risky, Somewhat Risky, Moderately Risky, Risky, Very Risky, Extremely Risky",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html#response-options",
    "href": "content/materials/scales/DOSPERT/dospert.html#response-options",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "Response options",
    "text": "Response options\nA 7-point Likert scale with all response options labeled (see instructions).",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html#download",
    "href": "content/materials/scales/DOSPERT/dospert.html#download",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/DOSPERT/dospert.html#reference",
    "href": "content/materials/scales/DOSPERT/dospert.html#reference",
    "title": "Domain-Specific Risk-Taking (DOSPERT) Scale",
    "section": "Reference",
    "text": "Reference\n\n\nBlais, A.-R., & Weber, E. U. (2006). A domain-specific risk-taking (DOSPERT) scale for adult populations. Judgment and Decision Making, 1(1), 33–47. https://doi.org/10.1017/S1930297500000334",
    "crumbs": [
      "Risk",
      "Domain-Specific Risk-Taking (DOSPERT) Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html",
    "href": "content/materials/scales/NEP/NEP.html",
    "title": "New Ecological Paradigm Scale",
    "section": "",
    "text": "The NEP is a 15-item measure of proenvironmental orientation. The revised NEP scale was designed to improve upon the original one in several respects:",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html#items",
    "href": "content/materials/scales/NEP/NEP.html#items",
    "title": "New Ecological Paradigm Scale",
    "section": "Items",
    "text": "Items\n\nWe are approaching the limit of the number of people the earth can support.\nHumans have the right to modify the natural environment to suit their needs.\nWhen humans interfere with nature it often produces disastrous consequences.\nHuman ingenuity will insure that we do NOT make the earth unlivable.\nHumans are severely abusing the environment.\nThe earth has plenty of natural resources if we just learn how to develop them.\nPlants and animals have as much right as humans to exist.\nThe balance of nature is strong enough to cope with the impacts of modern industrial nations.\nDespite our special abilities humans are still subject to the laws of nature.\nThe so-called “ecological crisis” facing humankind has been greatly exaggerated.\nThe earth is like a spaceship with very limited room and resources.\nHumans were meant to rule over the rest of nature.\nThe balance of nature is very delicate and easily upset.\nHumans will eventually learn enough about how nature works to be able to control it.\nIf things continue on their present course, we will soon experience a major ecological catastrophe.",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html#instructions",
    "href": "content/materials/scales/NEP/NEP.html#instructions",
    "title": "New Ecological Paradigm Scale",
    "section": "Instructions",
    "text": "Instructions\n\nListed below are statements about the relationship between humans and the environment. For each one, please indicate whether you STRONGLY AGREE, MILDLY AGREE, are UNSURE, MILDLY DISAGREE or STRONGLY DISAGREE with it.",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html#response-options",
    "href": "content/materials/scales/NEP/NEP.html#response-options",
    "title": "New Ecological Paradigm Scale",
    "section": "Response options",
    "text": "Response options\n\nStrongly agree\nMildly agree\nUnsure\nMildly disagree\nStrongly disagree",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html#download",
    "href": "content/materials/scales/NEP/NEP.html#download",
    "title": "New Ecological Paradigm Scale",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/NEP/NEP.html#reference",
    "href": "content/materials/scales/NEP/NEP.html#reference",
    "title": "New Ecological Paradigm Scale",
    "section": "Reference",
    "text": "Reference\n\n\nDunlap, R. E., Van Liere, K. D., Mertig, A. G., & Jones, R. E. (2000). New trends in measuring environmental attitudes: Measuring endorsement of the new ecological paradigm: A revised NEP scale. Journal of Social Issues, 56(3), 425–442. https://doi.org/10.1111/0022-4537.00176",
    "crumbs": [
      "Environmentalism",
      "New Ecological Paradigm Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/speciesism/speciesism.html",
    "href": "content/materials/scales/speciesism/speciesism.html",
    "title": "Speciesism Scale",
    "section": "",
    "text": "The Speciesism Scale is a 6-item measure of speciesism—the assignment of different inherent moral status based solely on an individual’s species membership.",
    "crumbs": [
      "Animals",
      "Speciesism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/speciesism/speciesism.html#items",
    "href": "content/materials/scales/speciesism/speciesism.html#items",
    "title": "Speciesism Scale",
    "section": "Items",
    "text": "Items\n\nMorally, animals always count for less than humans.\nHumans have the right to use animals however they want to.\nIt is morally acceptable to keep animals in circuses for human entertainment.\nIt is morally acceptable to trade animals like possessions.\nChimpanzees should have basic legal rights such as a right to life or a prohibition of torture.\nIt is morally acceptable to perform medical experiments on animals that we would not perform on any human.",
    "crumbs": [
      "Animals",
      "Speciesism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/speciesism/speciesism.html#response-options",
    "href": "content/materials/scales/speciesism/speciesism.html#response-options",
    "title": "Speciesism Scale",
    "section": "Response options",
    "text": "Response options\n\nStrongly disagree\nDisagree\nSomewhat disagree\nNeither agree nor disagree\nSomewhat agree\nAgree\nStrongly agree\n\n\n\n\n\n\n\nNote\n\n\n\nThe original paper only reports the labels for the end points of the scale (‘Strongly disagree’ and ‘Strongly agree’), not the options in between.",
    "crumbs": [
      "Animals",
      "Speciesism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/speciesism/speciesism.html#download",
    "href": "content/materials/scales/speciesism/speciesism.html#download",
    "title": "Speciesism Scale",
    "section": "Download",
    "text": "Download",
    "crumbs": [
      "Animals",
      "Speciesism Scale"
    ]
  },
  {
    "objectID": "content/materials/scales/speciesism/speciesism.html#reference",
    "href": "content/materials/scales/speciesism/speciesism.html#reference",
    "title": "Speciesism Scale",
    "section": "Reference",
    "text": "Reference\n\n\nCaviola, L., Everett, J. A. C., & Faber, N. S. (2019). The moral standing of animals: Towards a psychology of speciesism. Journal of Personality and Social Psychology, 116(6), 1011–1029. https://doi.org/10.1037/pspp0000182",
    "crumbs": [
      "Animals",
      "Speciesism Scale"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/reliability-validity.html",
    "href": "content/methodology/survey-design/reliability-validity.html",
    "title": "Reliability and validity",
    "section": "",
    "text": "A necessary but insufficient condition of measurement accuracy is producing consistent readings when measuring the same phenomenon.\nSelf-report scales must likewise be consistent, which psychometricians call reliability.\npsychometricians use various tests that examine consistency across individual items (internal reliability), random subsets of items (split-half reliability), scale versions (alternate-form reliability), perspectives (inter-rater reliability), time (test–retest reliability), and so forth (Anastasi & Urbina, 1997; Kazdin, 1998).\n\n\nThe most commonly examined type of reliability is internal reliability,\nMost scale builders also use the same arbitrary threshold of \u0002 \u0003 .70 to indicate scale reliability, though other more nuanced standards have been suggested. For example, DeVellis (2003, pp. 95–96) describes standards for what is unacceptable (\u0002 \u0004 .60), undesirable (.60 \u0004 \u0002 \u0004 .65), minimally acceptable (.65 \u0004 \u0002 \u0004 .70), respectable (.70 \u0004 \u0002 \u0004 .80), very good (.80 \u0004 \u0002 \u0004 .90), and unnecessarily high such that one should consider shortening one’s scale (.90 \u0004 \u0002)\nSee McNeish 2018\nstandardized \u0002 is a simple enough calculation: \u0002 \u0005 kr/(1 \u0006 r[k \u0007 1]). Both denominator and numerator are functions of the number of items in a scale (k) and mean interitem correlation (r),\nBecause \u0002 is determined exclusively by the number of items in a scale and the degree to which they covary, DeVellis (2003) accurately describes it as a proportion of covariance among items. John and Soto (2007) illustrate \u0002‘s dependence on these two attributes by noting \u0002 meets DeVellis’ (2003) standard of very good at .87 for both a six-item scale with a mean interitem correlation of .52 and a nine-item scale with a mean interitem correlation of .42.\nThis dependence on the number of items in a scale and the degree to which they covary also means that _ does not indicate validity\n\nThe reader might imagine a fictional nine-item scale involving a five-item set concerning gender and an orthogonal four-item set concerning hair color. If interitem correlations averaged .95 within sets and .00 between sets, the average correlation across all nine items would be .42, _ would be very good at .87, yet the scale would measure nothing.",
    "crumbs": [
      "Survey Design",
      "Reliability and validity"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/reliability-validity.html#reliability",
    "href": "content/methodology/survey-design/reliability-validity.html#reliability",
    "title": "Reliability and validity",
    "section": "",
    "text": "A necessary but insufficient condition of measurement accuracy is producing consistent readings when measuring the same phenomenon.\nSelf-report scales must likewise be consistent, which psychometricians call reliability.\npsychometricians use various tests that examine consistency across individual items (internal reliability), random subsets of items (split-half reliability), scale versions (alternate-form reliability), perspectives (inter-rater reliability), time (test–retest reliability), and so forth (Anastasi & Urbina, 1997; Kazdin, 1998).\n\n\nThe most commonly examined type of reliability is internal reliability,\nMost scale builders also use the same arbitrary threshold of \u0002 \u0003 .70 to indicate scale reliability, though other more nuanced standards have been suggested. For example, DeVellis (2003, pp. 95–96) describes standards for what is unacceptable (\u0002 \u0004 .60), undesirable (.60 \u0004 \u0002 \u0004 .65), minimally acceptable (.65 \u0004 \u0002 \u0004 .70), respectable (.70 \u0004 \u0002 \u0004 .80), very good (.80 \u0004 \u0002 \u0004 .90), and unnecessarily high such that one should consider shortening one’s scale (.90 \u0004 \u0002)\nSee McNeish 2018\nstandardized \u0002 is a simple enough calculation: \u0002 \u0005 kr/(1 \u0006 r[k \u0007 1]). Both denominator and numerator are functions of the number of items in a scale (k) and mean interitem correlation (r),\nBecause \u0002 is determined exclusively by the number of items in a scale and the degree to which they covary, DeVellis (2003) accurately describes it as a proportion of covariance among items. John and Soto (2007) illustrate \u0002‘s dependence on these two attributes by noting \u0002 meets DeVellis’ (2003) standard of very good at .87 for both a six-item scale with a mean interitem correlation of .52 and a nine-item scale with a mean interitem correlation of .42.\nThis dependence on the number of items in a scale and the degree to which they covary also means that _ does not indicate validity\n\nThe reader might imagine a fictional nine-item scale involving a five-item set concerning gender and an orthogonal four-item set concerning hair color. If interitem correlations averaged .95 within sets and .00 between sets, the average correlation across all nine items would be .42, _ would be very good at .87, yet the scale would measure nothing.",
    "crumbs": [
      "Survey Design",
      "Reliability and validity"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/reliability-validity.html#validity",
    "href": "content/methodology/survey-design/reliability-validity.html#validity",
    "title": "Reliability and validity",
    "section": "Validity",
    "text": "Validity\nvalidity concerns the degree to which the scale builder is measuring what she claims to be measuring. A bathroom scale can be consistent, for example, and consistently wrong.\nTypes of validity are even more undifferentiated and numerous than types of reliability. They include construct, content, concurrent, predictive, criterion, face, factorial, convergent, and discriminant validity (e.g., John & Soto, 2007; Kazdin, 1998).\nContent validity concerns the degree to which items denote the right construct, the entire construct, and nothing else.\nPredictive validity, sometimes called criterion-related validity, concerns the degree to which scale scores occupy the right spot in the nomological net or, as DeVellis (2003, p. 50) puts it, having the right empirical associations.",
    "crumbs": [
      "Survey Design",
      "Reliability and validity"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/reliability-validity.html#recommended-reading",
    "href": "content/methodology/survey-design/reliability-validity.html#recommended-reading",
    "title": "Reliability and validity",
    "section": "Recommended reading",
    "text": "Recommended reading\nDeVellis’ (2003)\nClifton 2020",
    "crumbs": [
      "Survey Design",
      "Reliability and validity"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/response-options.html",
    "href": "content/methodology/survey-design/response-options.html",
    "title": "Response Options",
    "section": "",
    "text": "Warning\n\n\n\nThis chapter is still a work in progress.\nThere are several decisions to make that involve response options. How many response options should you use? Should you use an even or odd number of response options? Should you label them? This section contains a summary of best practices that one can use to address these questions.",
    "crumbs": [
      "Survey Design",
      "Response Options"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/response-options.html#number-of-response-options",
    "href": "content/methodology/survey-design/response-options.html#number-of-response-options",
    "title": "Response Options",
    "section": "Number of Response Options",
    "text": "Number of Response Options\nThe question of how many response options to use centers around two main concerns. The first is that more options means you can obtain a more fine-grained assessment of the characteristic that is being evaluated (e.g., attitude). In other words, your assessment is more precise. However, the question is how the number of options affects the reliability and the validity of the measurement. With more options, it becomes more difficult for people to distinguish between the different options (e.g., is “Strongly agree” reliably different from “Very strongly agree”?).\nTable 1 shows an overview of various studies in which the topic of response options was addressed. The studies vary in many ways, so the final conclusion should be a holistic interpretation of the results, rather than a simple tallying of the results. Note also that only empirical studies are included and not simulation studies. Simulation studies seem limited because they cannot address the plausible psychological limitation of people being unable to distinguish between many options.\n\nTable 1: Overview of empirical studies on the topic of response options.\n\n\n\n\n\n\n\n\n\nSource\nComparisons\nTopic\nOutcome\nConclusion\n\n\n\n\nDonnellan & Rakhshani (2020)\n2- to 7-, and 11-point Likert\nSelf-esteem\nReliability; distribution; validity; quality\n5-point Likert or higher\n\n\nSimms et al. (2019)\n2- to 11-point Likert + VAS\nPersonality\nReliability; validity\n6-point Likert\n\n\nSung & Wu (2018)\n5-point Likert and VAS-RRP\nCareer interest\nReliability\nVAS-RPP\n\n\nCox et al. (2017)\n2- and 4-point Likert\nPersonality\nReliability; validity; duration\nMixed\n\n\nLewis (2017)\n7-, 11-point Likert and VAS\nSoftware usability\nReliability; distribution; validity\nNo difference\n\n\nKuhlmann et al. (2017)\n5-point Likert and VAS\nPersonality\nReliability; distribution; validity\nNo difference\n\n\nHilbert (2016)\n2- and 5-point and VAS\nPersonality\nReliability; validity; quality\nIt depends\n\n\nCapik & Gozum (2015)\n2- and 5-point Likert\nHealth\nReliability; validity\nNo difference\n\n\nEutsler & Lang (2015)\n5-, 7-, 9-, and 11-point Likert\nJudgment\nDistribution; power\n7-point Likert\n\n\nFinn et al. (2015)\n2- and 4-point Likert\n\n\n4-point Likert\n\n\nRevilla et al. (2014)\n5-, 7-, 11-point Likert\n\n\n5-point Likert\n\n\nCox et al. (2012)\n2- and 4-point Likert\n\n\n4-point Likert\n\n\nJanhunen (2012)\n7-point Likert and 30-point VAR\n\n\nVAR\n\n\nDawes (2008)\n5-, 7-, and 10-point Likert\n\n\nNo difference\n\n\nWeng (2004)\n3- to 9-point Likert\n\n\n5-point or higher\n\n\nPreston & Colman (2000)\n2- to 11-point Likert and VAS\n\n\n7-, 9-, or 10-point Likert\n\n\nAlwin (1997)\n7- and 11-point Likert\n\n\n11-point Likert\n\n\nJaeschke et al. (1990)\n7-point Likert and VAS\n\n\nNo difference\n(slightly favor 7-point Likert)\n\n\nFlamer (1983)\n2- and 9-point Likert\n\n\n9-point Likert\n\n\nMatell & Jacoby (1971)\n2-point to 18-point Likert\n\n\nNo difference\n\n\nBendig (1954)\n2-, 3-, 5-, 7-, and 9-point Likert\n\n\nNo difference\n(maybe 3-point or higher)\n\n\nRhemtulla et al. (2012)\n2- to 7-point Likert\n\n\n5-point Likert maybe good, 6- or 7-point best\n\n\n\nThere are also several review papers on the topic. Krosnick & Presser (2010) suggest that 7-point Likert scales are probably optimal. Lietz (2010) concludes a desirable Likert-scale consists of 5 to 8 response options. Similarly, Cox III (1980) recommends to use between 5 and 9 response options. Symonds (1924), in 1924, claims the optimum number is 7. Gehlbach & Brinkworth (2011) recommends using 5-points for unipolar items and 7-point for biopolar items.\nThere are also statistical arguments for why a particular number of response options is preferred. With more response options, the assumption of normality is more likely to be tenable. Some of the papers included in Table 1 (e.g., Rhemtulla et al. (2012)) are about this concern.\nBesides psychometric properties it may also be worth taking into account respondent preference. This involves ease of use of the scale and whether the response options allow for sufficient variation for respondents to express their view. Preston & Colman (2000) found that respondents found scales with 5, 7, and 10 points easy to use (compared to fewer options and a VAS) and that they preferred scales with more response options to allow them to express themselves (7 or more). Other studies also show that respondents favor more options (Cox et al., 2017).\nNote that if time is of the essence, fewer response options are preferred.\nAnother relevant factor is whether the scale is bipolar or unipolar. Bipolar scales are symmetrical which means the number of options naturally increase as they need to match both sides of the spectrum. Unipolar items are only about one side, usually ranging from the absence of something to the presence of something (to a certain degree). Since it is harder to label a larger number of options for a unipolar scale, the number of options are likely to be smaller.\nConclusion: It appears that few response options (2 or 3) should definitely be avoided. More response options therefore seems better, but benefits seem to quickly level off. Given other concerns, such as ease of use and interpretability, a 7-point Likert scale seems to be preferred for bipolar scales and a 5-point Likert scale for unipolar scales.",
    "crumbs": [
      "Survey Design",
      "Response Options"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/response-options.html#odd-vs.-even-response-options",
    "href": "content/methodology/survey-design/response-options.html#odd-vs.-even-response-options",
    "title": "Response Options",
    "section": "Odd vs. Even Response Options",
    "text": "Odd vs. Even Response Options\nThe middle option of a scale can have an ambiguous meaning. Participants may use it to indicate a moderate standing on the issue (Rugg and Cantril, 1944), a lack of an opinion (Nadler, Weston, and Voyles, 2014), ambivalence (Klopfer and Madden, 1980; Schaeﬀer and Presser, 2003; Nadler, Weston, and Voyles, 2014), indifference (Schaeﬀer and Presser, 2003; Nadler, Weston, and Voyles, 2014), uncertainty (Baka, Figgou, and Triga, 2012; Nadler, Weston, and Voyles, 2014), confusion, or to signal context dependence (e.g., “it depends” or disputing the question, see Baka, Figgou, and Triga, 2012).\nThe middle option may also be used for certain response styles, such as socially desirable responding (Sturgis, Roberts, and Smith, 2012) or satisficing (Krosnick, 1991), although there is not much research showing it actually leads to satisficing Wang & Krosnick (2020).\nAf a middle alternative is explicitly oﬀered, the proportion endorsing it increases dramatically (e.g. Ayidiya & McClendon, 1990; Bishop, 1987; Bishop, Hippler, Schwarz, & Strack, 1988; Kalton, Collins, & Brook, 1978; Kalton, Roberts, & Holt, 1980; Rugg & Cantril, 1944).\nSome studies show that not including a middle option decreases validity and increases measurement error (O’Muircheartaigh, Krosnick, and Helic, 1999; Kahn, and Dhar, 2002)\nRecent study on this: Wang & Krosnick (2020)\nAn alternative approach to this issue is to use branching. Respondents could first be asked whether they fall at the midpoint or on one side, followed by a question about their extremity on a side. This approach was found to be more reliable and valid than using a 7-point scale (Krosnick and Berent, 1993; Malhotra, Krosnick, and Thomas, 2009).\nConclusion: If it is possible that respondents may have a moderate view, it seems crucial for it to be possible to capture this view. Limitations of a middle option could then be addressed in other ways (e.g., clear questions).",
    "crumbs": [
      "Survey Design",
      "Response Options"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/response-options.html#response-option-labeling",
    "href": "content/methodology/survey-design/response-options.html#response-option-labeling",
    "title": "Response Options",
    "section": "Response Option Labeling",
    "text": "Response Option Labeling\nThere are several studies that show all response options should be labelled, rather than only labeling the end points (Krosnick & Berent, 1993; Weng, 2004).\nFor an example of biopolar labels for a 2- to 11-point Likert scale, see Table 1.\n\n\nTable 1: Likert response labels from Simms et al. (2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLabel\n2-point\n3-point\n4-point\n5-point\n6-point\n7-point\n8-point\n9-point\n10-point\n11-point\n\n\n\n\nVery strongly disagree\n\n\n\n\n\n\nx\nx\nx\nx\n\n\nStrongly disagree\n\n\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nDisagree\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nMostly disagree\n\n\n\n\n\n\n\n\nx\nx\n\n\nSlightly disagree\n\n\n\n\nx\nx\nx\nx\nx\nx\n\n\nNeither agree nor disagree\n\nx\n\nx\n\nx\n\nx\n\nx\n\n\nSlightly agree\n\n\n\n\nx\nx\nx\nx\nx\nx\n\n\nMostly agree\n\n\n\n\n\n\n\n\nx\nx\n\n\nAgree\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nStrongly agree\n\n\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nVery strongly agree\n\n\n\n\n\n\nx\nx\nx\nx\n\n\n\n\nIt is also recommended to avoid agree-disagree response labels because asking respondents to rate their level of agreement is a cognitively demanding task that increases respondent error and reduces responding effort (Gehlbach & Brinkworth, 2011).\nPossible labels, from CampusLabs:\nAgreement: Strongly agree, Moderately agree, Neither agree nor disagree, Moderately disagree, Strongly disagree (another version removes the “moderately” qualifier and/or uses “neutral”)\nComparison: Much X, Slightly X, About the same, Slightly (opposite of X), Much (opposite of X)\nEase: Very easy, Moderately easy, Neither easy nor difficult, Moderately difficult, Very difficult\nExpectations: Exceeds expectations, Fully meets expectations, Does not fully meet expectations, Does not meet expectations at all\nExtent (5 pt): A great deal (Completely, if appropriate), Considerably, Moderately, Slightly, Not at all\nExtent (4 pt): Significantly, Moderately, Slightly, Not at all\nFrequency (no set time): Always, Often, Occasionally, Rarely, Never\nFrequency (general): Daily, Weekly, Monthly, Once a semester, Once a year, Never\nFrequency (based on time frame): More than 5 times, 4 - 5 times, 2 - 3 times, 1 time, Less than 1 time, Never\nFrequency (extended): More than once a week, Once a week, Once a month, Once a semester, Once a year, Less than once a year, Never\nHelpfulness: Extremely helpful, Very helpful, Moderately helpful, Slightly helpful, Not at all helpful\nImportance: Extremely important, Very important, Moderately important, Slightly important, Not at all important\nInterest: Extremely interested, Very interested, Moderately interested, Slightly interested, Not at all interested\nLikelihood: Very likely, Moderately likely, Neither likely nor unlikely, Moderately unlikely, Very unlikely\nNumeric Scales: Less than #, About the same, More than #\nProbability: Definitely would, Probably would, Probably wouldn’t, Definitely wouldn’t\nProficiency: Beginner, Developing, Competent, Advanced, Expert (typical for Rubrics)\nQuality: Excellent, Good, Average, Below average, Poor\nSatisfaction: Very satisfied, Moderately satisfied, Neither satisfied nor dissatisfied, Moderately dissatisfied, Very dissatisfied (another version removes the “moderately” qualifier and/or uses “neutral”)\nTaken from https://baselinesupport.campuslabs.com/hc/en-us/articles/204305485-Recommended-Scales",
    "crumbs": [
      "Survey Design",
      "Response Options"
    ]
  },
  {
    "objectID": "content/methodology/survey-design/index.html",
    "href": "content/methodology/survey-design/index.html",
    "title": "Overview",
    "section": "",
    "text": "This chapter is about best practices and common issues in designing surveys.\nAs suggested in some review papers Simms (2008), the construction of a new survey or scale consists of several steps:\nI will try to cover as many of these topics as possible. Currently, there is a chapter on response options and one containing some recommended readings. There is also a Statistics section on this website that covers factor analyses.",
    "crumbs": [
      "Survey Design",
      "Overview"
    ]
  },
  {
    "objectID": "content/methodology/constructs/index.html",
    "href": "content/methodology/constructs/index.html",
    "title": "Overview",
    "section": "",
    "text": "This chapter is about how to best measure various constructs such as risk attitudes.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "content/WIP/item-development.html",
    "href": "content/WIP/item-development.html",
    "title": "Item Development",
    "section": "",
    "text": "Reverse-scored or reverse worded items can be included to determine whether participants are paying attention and don’t just select the same response on each item. However, there is some evidence that reverse-scored items reduce the reliability of the scale or produce an unexpected factor structure [@swain2008].\nAnother important consideration is that reverse-worded items can affect the model fit. Factor analyses of scales with some RW items frequently indicate the presence of method covariance obscuring or confounding substantive covariance (e.g., Brown, 2003; Roszkowski & Soven, 2010)."
  },
  {
    "objectID": "content/WIP/item-development.html#number-of-items",
    "href": "content/WIP/item-development.html#number-of-items",
    "title": "Item Development",
    "section": "Number of items",
    "text": "Number of items\nThere are no hard-and-fast rules guiding this decision, but keeping a measure short is an effective means of minimizing response biases caused by boredom or fatigue (Schmitt & Stults, 1985; Schriesheim & Eisenbach, 1990). Additional items also demand more time in both the development and administration of a measure (Carmines & Zeller, 1979). Harvey, Billings, and Nilan (1985) suggest that at least four items per scale are needed to test the homogeneity of items within each latent construct. Adequate internal consistency reliabilities can be obtained with as few as three items (Cook et al., 1981), and adding items indefinitely makes progressively less impact on scale reliability (Carmines & Zeller, 1979). It is difficult to improve on the internal consistency reliabilities of five appropriate items by adding items to a scale (Hinkin, 1985; Hinkin & Schriesheim, 1989; Schriesheim & Hinkin, 1990). Cortina (1993) found that scales with many\nitems may have high internal consistency reliabilities even if item intercorrelations are low, an argument in favor of shorter scales with high internal consistency. It is also important to assure that the domain has been adequately sampled, as inadequate sampling is a primary source of measurement error (Churchill, 1979). As Thurstone (1947) points out, scales should possess simple structure, or parsimony. Not only should any one measure have the simplest possible factor constitution, but any scale should require the contribution of a minimum number of items that adequately tap the domain of interest. These findings would suggest that the eventual goal will be the retention of four to six items for most constructs, but the final determination must be made only with accumulated evidence in support of the construct validity of the measure. It should be anticipated that approximately one half of the created items will be retained for use in the final scales, so at least twice as many items as will be needed in the final scales should be generated to be administered in a survey questionnaire.\nhttps://twitter.com/dingding_peng/status/1481683536499331079\nhttps://psyarxiv.com/4kra2/"
  }
]