[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"book organize conclusions topics methodology statistics.","code":""},{"path":"survey-design.html","id":"survey-design","chapter":"1 Survey design","heading":"1 Survey design","text":"chapter best practices common issues designing surveys.","code":""},{"path":"survey-design.html","id":"steps","chapter":"1 Survey design","heading":"1.1 Steps","text":"suggested review papers (e.g., Gehlbach Brinkworth (2011)), construction new survey/scale best done several steps:Review literature define construct interest find existing related measures constructReview literature define construct interest find existing related measures constructInterview respondents see whether respondents think way construct doInterview respondents see whether respondents think way construct doReconcile potential differences literature review interview dataReconcile potential differences literature review interview dataDevelop items (see next sections details best design items)Develop items (see next sections details best design items)Validate expertsValidate expertsDo cognitive pretesting see respondents understand respond itemDo cognitive pretesting see respondents understand respond itemRun large-scaled reliability validity testsRun large-scaled reliability validity tests","code":""},{"path":"survey-design.html","id":"item-development","chapter":"1 Survey design","heading":"1.2 Item development","text":"","code":""},{"path":"survey-design.html","id":"reverse-scored-items","chapter":"1 Survey design","heading":"Reverse-scored items","text":"Reverse-scored items can included determine whether participants paying attention don’t just select response item. However, evidence reverse-scored items reduce reliability scale produce unexpected factor structure (Swain, Weathers, Niedrich 2008).","code":""},{"path":"survey-design.html","id":"response-options","chapter":"1 Survey design","heading":"Response options","text":"question many response options use centers around two main concerns. first options means can obtain fine-grained assessment characteristic evaluated (e.g., attitude). words, assessment precise. However, question number options affects reliability validity measurement. options, becomes difficult people distinguish different options (e.g., “Strongly agree” reliably different “strongly agree?”).Table 1 shows overview various studies topic response options addressed. studies vary many ways, final conclusion holistic interpretation results, rather simple tallying results. Note also empirical studies included simulation studies. Simulation studies seem limited address plausible psychological limitation people unable distinguish many options.Table 1: Overview empirical studies topic response options.also several review papers topic. Krosnick Presser (2010) suggest 7-point Likert scales probably optimal. Lietz (2010) concludes desirable Likert-scale consists 5 8 response options. Similarly, Cox III (1980) recommends use 5 9 response options. Symonds (1924), 1924, claims optimum number 7. Gehlbach Brinkworth (2011) recommends using 5-points unipolar items 7-point biopolar items.Besides psychometric properties may also worth taking account respondent preference. involves ease use scale whether response options allow sufficient variation respondents express view. Preston Colman (2000) found respondents found scales 5, 7, 10 points easy use (compared fewer options VAS) preferred scales response options allow express (7 ). studies also show respondents favor options (Cox et al. 2017).Note time essence, fewer response options preferred.Conclusion: appears response options (2 3) definitely avoided. response options therefore seems better, benefits seem quickly level . Given concerns, ease use interpretability, 7-point Likert scale seems preferred.","code":""},{"path":"survey-design.html","id":"odd-vs.-even-response-options","chapter":"1 Survey design","heading":"Odd vs. even response options","text":"middle option scale can ambiguous meaning. Participants may use indicate moderate standing issue, indicate uncertainty, indicate confusion, signal context dependence (e.g., “depends”).middle option may also used social desirable responding.Conclusion: possible respondents may moderate view, seems crucial possible capture view. Limitations middle option addressed ways (e.g., clear questions).","code":""},{"path":"survey-design.html","id":"response-option-labeling","chapter":"1 Survey design","heading":"Response option labeling","text":"several studies show response options labelled, rather labeling end points (Weng 2004; Krosnick Berent 1993).example biopolar labels 2- 11-point Likert scale, see Table 1.Table 1: Likert response labels Simms et al. (2019)also recommended avoid agree-disagree response labels asking respondents rate level agreement cognitively demanding task increases respondent error reduces responding effort (Gehlbach Brinkworth 2011).","code":""},{"path":"survey-design.html","id":"recommended-reading","chapter":"1 Survey design","heading":"1.3 Recommended reading","text":"following papers useful overview review papers , mind, particular useful read.Measure twice, cut error: process enhancing validity survey scales Gehlbach Brinkworth (2011)","code":""},{"path":"factor-analysis.html","id":"factor-analysis","chapter":"2 Factor analysis","heading":"2 Factor analysis","text":"","code":""},{"path":"factor-analysis.html","id":"exploratory-factor-analyses","chapter":"2 Factor analysis","heading":"2.1 Exploratory factor analyses","text":"goal exploratory factor analysis (EFA) study latent factors underlie responses larger number measures items. popular technique development validation assessment instruments. Unlike confirmatory factor analysis, EFA used little priori justification specifying particular structural model. means number underlying factors determined mostly empirically, rather theoretically.","code":""},{"path":"factor-analysis.html","id":"principal-components-vs.-factor-analysis","chapter":"2 Factor analysis","heading":"2.1.1 Principal Components vs. Factor Analysis","text":"important consideration whether use Principal Components Analyses (PCA) factor analyses.PCA data reduction technique. conceptualizes constructs causally determined observations (Edwards & Bagozzi, 2000). likely want means “principal component scores ”caused” indicators much way sumscores “caused” item scores.” \\[@borsboom2006\\]. Instead, likely want opposite causal relationship latent factor causes indicator scores.partitioning variance differentiates principal components analysis call common factor analysis. methods try reduce dimensionality dataset fewer unobserved variables, whereas PCA assumes common variances takes total variance, common factor analysis assumes total variance can partitioned common unique variance. usually reasonable assume measured set items perfectly. unobserved latent variable makes common variance called factor, hence name factor analysis. main difference PCA factor analysis lies goal analysis. goal simply reduce variable list linear combination smaller components PCA way go. However, believe latent construct defines interrelationship among items, factor analysis may appropriate.","code":""},{"path":"factor-analysis.html","id":"sample-size","chapter":"2 Factor analysis","heading":"2.1.2 Sample size","text":"","code":""},{"path":"factor-analysis.html","id":"rules-of-thumb","chapter":"2 Factor analysis","heading":"2.1.2.1 Rules of thumb","text":"general consensus seems rules thumb bad idea. reason rules involve one two factors. Common rules thumb consist going set number participants particular participant--item ratio.Table: Examples rules thumb.reality sample size dependent :study design (e.g., cross-sectional vs. longitudinal)study design (e.g., cross-sectional vs. longitudinal)size relationships among indicators (e.g., high communalities without cross loadings; strong loadings)size relationships among indicators (e.g., high communalities without cross loadings; strong loadings)reliability indicatorsthe reliability indicatorsthe scaling (e.g., categorical, continuous) distribution indicatorsthe scaling (e.g., categorical, continuous) distribution indicatorsestimator type (e.g., ML, robust ML, WLSMV)estimator type (e.g., ML, robust ML, WLSMV)amount patterns missing datathe amount patterns missing datathe size model (model complexity)size model (model complexity)Costello Osborne (2005) caution researchers remember EFA large-sample procedure generalizable replicable results unlikely sample small. found ratio 20:1 produces error rates well standard alpha (5%) level.","code":""},{"path":"factor-analysis.html","id":"sampling-adequacy","chapter":"2 Factor analysis","heading":"2.1.3 Sampling Adequacy","text":"Kaiser–Meyer–Olkin (KMO) test statistical measure determine suited data factor analysis. test measures sampling adequacy variable model complete model. statistic measure proportion variance among variables might common variance. lower proportion, higher KMO value, suited data factor analysisThe KMO value ranges 0 1, 0.60 considered suitable factor analysis Tabachnick Fidell (2013). Kaiser (1974) suggested KMO > .9 marvelous, .80s, mertitourious, .70s, middling, .60s, medicore, 50s, miserable, less .5, unacceptable.Bartlett’s (1954) test sphericity notoriously sensitive test hypothesis correlations correlation matrix zero. sensitivity dependence N, test likely significant samples substantial size even correlations low. Therefore, use test recommended fewer , say, five cases per variable (Tabachnick Fidell 2013).","code":""},{"path":"factor-analysis.html","id":"outlier-removal","chapter":"2 Factor analysis","heading":"2.1.4 Outlier removal","text":"remove outliers?","code":""},{"path":"factor-analysis.html","id":"number-of-factors-to-retain","chapter":"2 Factor analysis","heading":"2.1.5 Number of factors to retain","text":"several methods determine many factors retain:Kaiser criterion (eigenvalues greater 1; Kaiser, 1960)Kaiser criterion (eigenvalues greater 1; Kaiser, 1960)Scree test (Cattell, 1966)Scree test (Cattell, 1966)Parallel analysis (Horn, 1965)Parallel analysis (Horn, 1965)Velicer’s multiple average partial (MAP) procedure (Velicer, 1976)Velicer’s multiple average partial (MAP) procedure (Velicer, 1976)Akaike information criterion (AIC; Akaike, 1974)Akaike information criterion (AIC; Akaike, 1974)Bayesian information criterion (BIC; Schwarz, 1978)Bayesian information criterion (BIC; Schwarz, 1978)Comparison data (CD; Ruscio Brendan Roche (2012))Comparison data (CD; Ruscio Brendan Roche (2012))Simple Structure (VSS)Simple Structure (VSS)default statistical software packages retain factors eigenvalues greater 1. broad consensus literature among least accurate methods selecting number factors retain (Velicer & Jackson, 1990).Zwick Velicer (1986) tested scree test, Horn’s parallel test, Velicer’s MAP test (among others) simulation studies using data set clear factor structure. parallel test minimum average partial test seemed work well.Ruscio Brendan Roche (2012) notes PA considered method choice among methodologists recommend researchers take advantage PA starting point, perhaps supplemented CD. note researchers can also use one method. Similarly, several prominent authors journals endorsed robust accurate process determining number factors extract (Ledesma & Valero-Mora, 2007; Velicer et al., 2000).Osborne (2014) notes MAP considered superior “classic” criteria, probably superior parallel analysis, although neither perfect, must used context search conceptually interpretable factors. recommends use parallel analysis MAP criteria, along theory (classic criteria suits defensible).TODO: Look VSS.","code":""},{"path":"factor-analysis.html","id":"factor-extraction-method","chapter":"2 Factor analysis","heading":"2.1.6 Factor Extraction Method","text":"multiple factor extract methods, :minresminresunweighted least squaresunweighted least squaresgeneralized least squaresgeneralized least squaresmaximum likelihoodmaximum likelihoodprincipal axis factoringprincipal axis factoringalpha factoringalpha factoringimage factoring.image factoring.Advice use maximum likelihood method data generally normally distributed use principal axis factoring data non-normal (Costello Osborne (2005), Osborne (2014)).","code":""},{"path":"factor-analysis.html","id":"rotation-methods","chapter":"2 Factor analysis","heading":"2.1.7 Rotation methods","text":"several rotation methods. can categorized one categories: orthogonal oblique.Orthogonal rotation methods include:varimaxvarimaxquartimaxquartimaxequamaxequamaxOblique rotation methods include:direct oblimindirect obliminquartiminquartiminpromaxpromaxIn social sciences generally expect correlation among factors, since behavior rarely partitioned neatly packaged units function independently one another. Therefore using orthogonal rotation results loss valuable information factors correlated, oblique rotation theoretically render accurate, perhaps reproducible, solution. factors truly uncorrelated, orthogonal oblique rotation produce nearly identical results. Since oblique rotation reproduce orthogonal solution vice versa, recommend oblique rotation.widely preferred method oblique rotation; tend produce similar results (Fabrigar et al., 1999)","code":""},{"path":"factor-analysis.html","id":"factor-structure","chapter":"2 Factor analysis","heading":"2.1.8 Factor structure","text":"Tabachnick Fidell (2001) cite .32 good rule thumb minimum loading item. Others say item loadings .30 (Costello).Others say factor loading coefficient ≥ 0.40 considered necessary judge quality (validity) item indicator one factor another. may think criterion quite lax since factor loading 0.40 means 16% explained variance depends factor one item indicator (Gana & Broc)psychometricians (example, \\[COM 92, TAB 07\\]) recommend choose items whose R² greater 0.40 (thus showing factorial factor loading greater 0.63).“crossloading” item item loads .32 higher two factors. researcher needs decide whether crossloading item dropped analysis, may good choice several adequate strong loaders (.50 better) factor.\nfactor fewer three items generally weak unstable; 5 strongly loading items (.50 better) desirable indicate solid factor.“crossloading” item item loads .32 higher two factors. researcher needs decide whether crossloading item dropped analysis, may good choice several adequate strong loaders (.50 better) factor.factor fewer three items generally weak unstable; 5 strongly loading items (.50 better) desirable indicate solid factor., important latent variable least four indicators (example: four items). effect, three indicators, measurement model just-identified, thus making useless testability. (Gana & Broc), important latent variable least four indicators (example: four items). effect, three indicators, measurement model just-identified, thus making useless testability. (Gana & Broc)Comrey Lee (1992) suggest loadings excess .71 (50% overlapping variance) considered excellent, .63 (40% overlapping variance) good, .55 (30% overlapping variance) good, .45 (20% overlapping variance) fair, .32 (10% overlapping variance) poor.","code":""},{"path":"factor-analysis.html","id":"confirmatory-factor-analysis","chapter":"2 Factor analysis","heading":"2.2 Confirmatory factor analysis","text":"confirmatory factor analyses also several ways determine sample size, including:Rules thumbSatorra-Saris methodMonte Carlo approach","code":""},{"path":"factor-analysis.html","id":"estimator","chapter":"2 Factor analysis","heading":"2.2.1 Estimator","text":"data normally distributed, use ML estimator.findings Chou Bentler \\[CHO 95\\] make possible qualify remarks. authors showed presence sufficiently large sample, maximum likelihood estimation method generalized least squares method make results suffer, even multivariate normality slightly violated.case violations, following estimators can used:MLMMLMMLR: Similar MLM better suited small sample sizes (Gana & Broc).MLR: Similar MLM better suited small sample sizes (Gana & Broc).weighted least squares method (WLS): Requires large sample size (FLO 04) frequently runs convergence issues improper solutionsweighted least squares method (WLS): Requires large sample size (FLO 04) frequently runs convergence issues improper solutionsDiagonally Weighted Least Squares (DWLS): small samples non-normal data ([JÖR 89)Diagonally Weighted Least Squares (DWLS): small samples non-normal data ([JÖR 89)WLSM: Robust alternative DWLSWLSM: Robust alternative DWLSWLSMV: Robust alternative DWLSWLSMV: Robust alternative DWLSbootstrapping: recommended dichotomous ordinal measures response categories)bootstrapping: recommended dichotomous ordinal measures response categories)Mardia calculation determine violations normal distribution. can noted standardized coefficient statistically significant, value greater 5, threshold value beyond multivariate normality seems fail \\[KLI 16\\].Recommendations concerning main estimators available lavaan according type data (Gana & Broc).","code":""},{"path":"factor-analysis.html","id":"fit-indices","chapter":"2 Factor analysis","heading":"2.2.2 Fit indices","text":"advice can afford give, however, closely follow developments concerning fit indices. meantime, can carefully follow recommendations Hu Bentler \\[HU 99\\] Schreiber co-authors \\[SCH 06\\] suggest following guidelines judging model goodness--fit (based hypothesis maximum likelihood method estimation method): 1) RMSEA value ≤ 0.06, confidence interval 90% values 0 1.00; 2) SRMR value ≤ 0.08; 3) CFI TLI values ≥ 0.95.Fit indices guidance Gana Broc (2019)","code":""},{"path":"factor-analysis.html","id":"reliability","chapter":"2 Factor analysis","heading":"2.2.3 Reliability","text":"Reliability increases closer value gets 1.00, acceptability threshold 0.70.","code":""},{"path":"factor-analysis.html","id":"examples","chapter":"2 Factor analysis","heading":"2.3 Examples","text":"Beyond Sacrificial Harm: Two-Dimensional Model Utilitarian Psychology","code":""},{"path":"factor-analysis.html","id":"r-packages","chapter":"2 Factor analysis","heading":"2.4 R packages","text":"lavaanlavaanlavaan.surveylavaan.surveysemToolssemToolssemPowersemPower","code":""},{"path":"factor-analysis.html","id":"useful-links","chapter":"2 Factor analysis","heading":"2.5 Useful links","text":"https://stats.idre.ucla.edu/spss/seminars/introduction--factor-analysis/-practical-introduction--factor-analysis/","code":""},{"path":"data-visualization.html","id":"data-visualization","chapter":"3 Data Visualization","heading":"3 Data Visualization","text":"","code":""},{"path":"data-visualization.html","id":"bar-charts","chapter":"3 Data Visualization","heading":"3.1 Bar charts","text":"","code":"\np <- ggplot(mpg, aes(x = class, fill = class)) +\n  geom_bar(alpha = .85) +\n  scale_fill_viridis(discrete = TRUE, option = \"mako\", end = .95) +\n  theme_rethink()\n\nggplotly(p)"},{"path":"data-visualization.html","id":"line-charts","chapter":"3 Data Visualization","heading":"3.2 Line charts","text":"","code":"\np <- ggplot(economics, aes(x = date, y = unemploy)) + \n  geom_line() +\n  theme_rethink()\n\nggplotly(p)\np <- ggplot(economics_long, aes(x = date, y = value01, \n    color = variable)) +\n  geom_line() +\n  scale_color_viridis(discrete = TRUE, option = \"mako\", end = .95) +\n  theme_rethink()\n\nggplotly(p)"},{"path":"data-visualization.html","id":"scatter-plots","chapter":"3 Data Visualization","heading":"3.3 Scatter plots","text":"","code":"\np <- ggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point(alpha = .85) +\n  theme_rethink()\n\nggplotly(p)\np <- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(alpha = .85) +\n  scale_color_viridis(discrete = TRUE, option = \"mako\", end = .95) +\n  theme_rethink()\n\nggplotly(p)"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
