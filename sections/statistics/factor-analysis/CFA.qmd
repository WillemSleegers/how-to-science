---
title: "Confirmatory Factor Analysis"
bibliography: references.bib
---

::: callout-warning
This chapter is still a work in progress.
:::

Note that if you have a clear theoretical basis about the number of factors and which items should load on which factor, CFA is more appropriate than EFA because it allows you to directly test your model. You could also do both, but a CFA should be conducted on new data to test its validity.

To incorporate:

-   https://github.com/zackfisher/MIIVsem

-   https://doi.apa.org/doiLanding?doi=10.1037%2Fmet0000297

-   

For confirmatory factor analyses there are also several ways to determine the sample size, including:

1.  Rules of thumb
2.  Satorra-Saris method
3.  Monte Carlo approach

### Number of indicators

Some argue that when it comes to the number of indicators, more is better @marsh1998.

Others say that more is not always better [@koran2020]. @koran2020, using a simulation study, showed that:

> Models with relatively weak loadings tended to have a larger desirable number of indicators per factor than models with stronger loadings based on considerations of sample size, solution propriety, bias, and power. Models with few factors also tended to have a larger desirable number of indicators per factor than models with more factors. Models with many factors and strong indicators reached a minimum required sample size with as few as three indicators per factor.

### Estimator

If the data is normally distributed, use the ML estimator.

the findings of Chou and Bentler make it possible to qualify these remarks. These authors showed that in the presence of a sufficiently large sample, maximum likelihood estimation method and generalized least squares method do not make the results suffer, even when the multivariate normality is slightly violated.

In case of violations, the following estimators can be used:

-   MLM

-   MLR: Similar to MLM but better suited for small sample sizes (Gana & Broc).

-   weighted least squares method (WLS): Requires a large sample size (FLO 04) and frequently runs into convergence issues and improper solutions

-   Diagonally Weighted Least Squares (DWLS): For small samples and non-normal data (\[JÃ–R 89)

-   WLSM: Robust alternative to DWLS

-   WLSMV: Robust alternative to DWLS

-   bootstrapping: Not recommended for dichotomous and ordinal measures with few response categories)

Mardia calculation to determine violations from normal distribution. It can be noted that not only is this standardized coefficient statistically significant, but its value is greater than 5, which is the threshold value beyond which multivariate normality seems to fail.

| Data type and normality assumption | Recommended estimator                            |
|------------------------------------|--------------------------------------------------|
| *Continuous data*                  |                                                  |
| Approximately normal distribution  | ML                                               |
| Violation of normality assumption  | ML (in case of moderate violation)               |
|                                    | MLM, MLR, Bootstrap                              |
| *Ordinal/categorical data*         |                                                  |
| Approximately normal distribution  | ML (if at least 6 response categories)           |
|                                    | MLM, MLR (if at least 4 response categories)     |
|                                    | WLSMV (binary response or 3 response categories) |
| Violation of normality assumption  | ML (if at least 6 response categories)           |
|                                    | MLM, MLR (if at least 4 response categories)     |
|                                    | WLSMV (in case of severe violation)              |

: Recommendations concerning the main estimators available in lavaan according to the type of data (Gana & Broc).

### Assessing model fit

Probably the most common way to assess model fit is to rely on cut-off points for several fit indices. However, these cut off points make no sense. The reason is that the suitability of a particular model fit index depends on a multitude of factors, including the number of items per factor, factor loading size, type of misspecification, model type, and violations of multivariate normality [@greiff2017]. It therefore makes no sense to use one cut-off point for all models.

Instead, it is recommend to do the following:

Step 1: Perform the chi squared test and see whether it indicates a significant misfit. Although it appears that the norm is to ignore a significant chi squared test, it seems that is considered to be a mistake, leading to many misfitted models to not be rejected \[@barrett2007, @mcintosh2007\].

Step 2: In the case of a significant chi squared test, inspect potential sources of misfit.

-   If your model depends on the multivariate normality assumption, look for signs of a violation of this assumption. Given that much research is done using Likert scales, this could be a likely source. To solve this misfit issue, one can transform the data or use a different estimator.

-   Inspect the discrepancies between the observed and model-implied covariance matrices.

-   Use tools to locate misfits, such as looking at modification indices or performing Fisher's C test or the Wald test.

Note that it is important to avoid the problem of overfitting. Any modifications to the model should be tested again on new independent data.

The modifications should also have a theoretical backing.

Finally, although it should not be necessary to point this out, but it is possible to be wrong. You may have to conclude that the data simply does not support your theory and that you need to go back to the drawing board.

### Reliability

Reliability increases the closer the value gets to 1.00, with an acceptability threshold of 0.70.

### How to model reverse-worded items?

## Recommended Reading

-   Dynamic Fit Index Cutoffs for Confirmatory Factor Analysis Models by @mcneish2021
